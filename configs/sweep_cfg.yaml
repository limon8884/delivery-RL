name: fourth_sweep
method: bayes
metric:
  goal: maximize
  name: CR
parameters:
  n_envs: 
    value: 8
  trajectory_lenght: 
    values: [2000, 3000]
  batch_size: 
    values: [32, 64, 128]
  num_epochs_per_traj:
    min: 6
    max: 14
  max_num_points_in_route:
    value: 2
  sampler_mode:
    value: "dummy_sampler"
  learning_rate:
    value: 0.0003
  optimizer: 
    value: "adam"
  # rmsprop_alpha:
  #   values: [0.9, 0.99, 0.999]
  # sgd_momentum: 
  #   value: 0.8
  scheduler_max_lr: 
    distribution: "log_uniform"
    min: -14.0
    max: -7.0
  scheduler_pct_start: 
    min: 0.1
    max: 0.4
  exploration_temperature:
    distribution: "log_uniform"
    min: -2.0
    max: 2.0
  ppo_cliprange: 
    min: 0.05
    max: 0.3
  ppo_value_loss_coef:
    distribution: "log_uniform"
    min: -4.5
    max: 4.5
  ppo_entropy_loss_coef:
    distribution: "log_uniform"
    min: -4.5
    max: 4.5
  max_grad_norm:
    value: 1.0
  gae_gamma: 
    values: [0.9, 0.95, 0.99, 0.995, 0.999]
  gae_lambda:
    values: [0.9, 0.95, 0.99, 0.995, 0.999]
  reward_norm_gamma:
    values: [0.9, 0.95, 0.99, 0.995, 0.999]
  reward_norm_cliprange:
    values: [1.0, 10.0]
  coef_reward_assigned:
    distribution: "log_uniform"
    min: -2.0
    max: 2.0
  coef_reward_cancelled:
    distribution: "log_uniform"
    min: -2.0
    max: 2.0
  total_iters:
    value: 25000
  device: 
    value: "cuda"
  use_wandb: 
    value: true
  use_train_logs:
    value: false
  eval_epochs_frequency: 
    value: 1000