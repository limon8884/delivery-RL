{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from dispatch.dispatch import Dispatch, NeuralDispatch\n",
    "from simulator.base_simulator import BaseSimulator, ManualSimulator\n",
    "from simulator.simulator import Simulator\n",
    "from simulator.graphics import plot_CR, plot_counts\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from networks.encoders import PointEncoder\n",
    "from networks.scoring_v1 import ScoringNet, ScoringInterface\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import nn\n",
    "from torchrl.collectors import SyncDataCollector, MultiaSyncDataCollector, MultiSyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import (\n",
    "    Compose,\n",
    "    DoubleToFloat,\n",
    "    ObservationNorm,\n",
    "    StepCounter,\n",
    "    TransformedEnv,\n",
    ")\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs.utils import check_env_specs, set_exploration_mode\n",
    "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
    "from torchrl.objectives import ClipPPOLoss\n",
    "from torchrl.objectives.value import GAE\n",
    "from torchrl.envs import EnvBase\n",
    "from tensordict.tensordict import TensorDictBase, TensorDict\n",
    "from typing import Optional\n",
    "import gym\n",
    "from torchrl.data import CompositeSpec, BoundedTensorSpec, UnboundedContinuousTensorSpec, BinaryDiscreteTensorSpec, OneHotDiscreteTensorSpec, DiscreteTensorSpec, UnboundedDiscreteTensorSpec\n",
    "\n",
    "# import importlib\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "num_cells = 256  # number of cells in each layer\n",
    "lr = 3e-4\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "frame_skip = 1\n",
    "frames_per_batch = 1000 // frame_skip\n",
    "# For a complete training, bring the number of frames up to 1M\n",
    "total_frames = 200_000 // frame_skip\n",
    "\n",
    "sub_batch_size = 4  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
    "num_epochs = 10  # optimisation steps per batch of data collected\n",
    "clip_epsilon = (\n",
    "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
    ")\n",
    "gamma = 0.99\n",
    "lmbda = 0.95\n",
    "entropy_eps = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ScoringNet(\n",
    "    mode='default',\n",
    "    # point_encoder=point_encoder,\n",
    "    n_layers=2,\n",
    "    d_model=512,\n",
    "    n_head=4,\n",
    "    dim_ff=512,\n",
    "    point_enc_dim=64,\n",
    "    number_enc_dim=8,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "model = ScoringInterface(net)\n",
    "# model.load_weights('pretrained_models/assignment_cloning_model_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 9, 12]) torch.Size([4, 9, 11])\n"
     ]
    }
   ],
   "source": [
    "bounds = (Point(0, 0), Point(10, 10))\n",
    "triples = [random_triple(bounds) for _ in range(sub_batch_size)]\n",
    "\n",
    "model.encode_input(triples, 0)\n",
    "preds = model.inference()\n",
    "mask = model.get_mask()\n",
    "\n",
    "print(preds.shape, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode_input(triples[0], 0)\n",
    "model.get_mask().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.777982711791992]\n",
      "[23.777982711791992, 11.678504943847656]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.net.parameters(), lr=1e-4, momentum=0.9) # FIX unfreeze encoder params\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, epochs=n_epochs, steps_per_epoch=n_iters)\n",
    "scheduler = None\n",
    "\n",
    "losses = []\n",
    "for epoch in range(2):\n",
    "    for iter in range(10):\n",
    "        rolling_loss = []\n",
    "        triples = [random_triple(bounds) for _ in range(sub_batch_size)]\n",
    "\n",
    "        scorer = ETAScoring()\n",
    "        solver = HungarianSolver()\n",
    "        assignments = []\n",
    "        for triple in triples:\n",
    "            scores = scorer(triple.orders, triple.couriers)\n",
    "            assignments.append([(i, j) for i, j in zip(*solver(scores))])\n",
    "\n",
    "        # print(assignments)\n",
    "        # print(50 * '-')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.encode_input(triples, 0)\n",
    "        model.inference()\n",
    "        loss = model.CE_loss(assignments)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        rolling_loss.append(loss.item())\n",
    "\n",
    "    losses.append(np.mean(rolling_loss))\n",
    "\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'environment_config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb Cell 7\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# dsp = NeuralDispatch(net)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dsp \u001b[39m=\u001b[39m Dispatch()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m sim \u001b[39m=\u001b[39m Simulator()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m all_metrics \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m)):\n",
      "File \u001b[0;32m~/PycharmProjects/delivery-RL/delivery-RL/simulator/simulator.py:120\u001b[0m, in \u001b[0;36mSimulator.__init__\u001b[0;34m(self, step, seed)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSetSeed(seed)\n\u001b[0;32m--> 120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mInitialize()\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinished_couriers \u001b[39m=\u001b[39m []\n\u001b[1;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinished_orders \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/PycharmProjects/delivery-RL/delivery-RL/simulator/simulator.py:134\u001b[0m, in \u001b[0;36mSimulator.Initialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mInitialize\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mconfigs/simulator_settings.json\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv_config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m    137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimer \u001b[39m=\u001b[39m Timer()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'environment_config.json'"
     ]
    }
   ],
   "source": [
    "# dsp = NeuralDispatch(net)\n",
    "dsp = Dispatch()\n",
    "sim = Simulator()\n",
    "\n",
    "all_metrics = []\n",
    "for i in tqdm(range(1000)):\n",
    "    metrics = sim.GetMetrics()\n",
    "    all_metrics.append(metrics)\n",
    "    state = sim.GetState()\n",
    "    sim.Next(dsp(state))\n",
    "\n",
    "plot_CR(all_metrics)\n",
    "plot_counts(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dsp = NeuralDispatch(net)\n",
    "# dsp = Dispatch()\n",
    "# sim = ManualSimulator()\n",
    "\n",
    "# all_metrics = []\n",
    "# for i in tqdm(range(1000)):\n",
    "#     metrics = sim.GetMetrics()\n",
    "#     all_metrics.append(metrics)\n",
    "#     ass = dsp(sim.GetState())\n",
    "#     sim.Next(ass)\n",
    "\n",
    "# plot_CR(all_metrics)\n",
    "# plot_counts(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.tensors['o'].shape\n",
    "model.masks['o'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COURIERS = 50\n",
    "\n",
    "class SimulatorEnv(EnvBase):\n",
    "    def __init__(self, simulator: type[Simulator], seed=None, device=\"cpu\"):\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "        # self.simulators = [simulator(seed=i) for i in range(sub_batch_size)]\n",
    "        self.simulator = simulator()\n",
    "        self.model = ScoringInterface(net)\n",
    "        # triples = [simulator.GetState() for simulator in self.simulators]\n",
    "        # self.model.encode_input(triples, 0)\n",
    "        triple = self.simulator.GetState()\n",
    "        self.model.encode_input(triple, 0)\n",
    "        self._make_specs()\n",
    "        \n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.long).random_().item()\n",
    "        self.set_seed(seed)\n",
    "        \n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        '''\n",
    "        tensordict['action'] - a np.array of indexes of couriers assigned for the given order. If there is no courier assigned -1 is provided.\n",
    "        BOS-fake items are included.\n",
    "        '''\n",
    "\n",
    "        # BATCH MODE\n",
    "        # for batch_idx in range(sub_batch_size):\n",
    "        #     assignments = []\n",
    "        #     assigned_o_idxs = set()\n",
    "        #     assigned_c_idxs = set()\n",
    "        #     for o_idx, c_idx in enumerate(tensordict['action'][batch_idx].numpy()):\n",
    "        #         if c_idx != - 1 \\\n",
    "        #             and not tensordict['observation', 'masks', 'o'][batch_idx][o_idx] \\\n",
    "        #             and not tensordict['observation', 'masks', 'c'][batch_idx][c_idx] \\\n",
    "        #             and (o_idx not in assigned_o_idxs) and (c_idx not in assigned_c_idxs) \\\n",
    "        #         :\n",
    "        #             assignment = (tensordict['observation', 'ids', 'o'][batch_idx][o_idx].item(), tensordict['observation', 'ids', 'c'][batch_idx][c_idx].item())\n",
    "        #             assignments.append(assignment)\n",
    "        #             assigned_o_idxs.add(o_idx)\n",
    "        #             assigned_c_idxs.add(c_idx)\n",
    "\n",
    "        #     self.simulators[batch_idx].Next(assignments)\n",
    "\n",
    "        # print(tensordict.flatten_keys())\n",
    "        # print(tensordict['observation', 'masks', 'o'])\n",
    "        # print(tensordict['observation', 'ids', 'o'])\n",
    "        # print(tensordict['observation', 'masks', 'c'])\n",
    "        # print(tensordict['observation', 'ids', 'c'])\n",
    "        # print(tensordict['action'])\n",
    "\n",
    "        assignments = []\n",
    "        assigned_o_idxs = set()\n",
    "        assigned_c_idxs = set()\n",
    "        for o_idx, c_idx in enumerate(tensordict['action'].numpy()):\n",
    "            if c_idx >= self.model.ids['c'].shape[-1]:\n",
    "                print('WARNING!\\n\\nc_idx increases MAX_LIMIT')\n",
    "                continue\n",
    "            if c_idx != - 1 \\\n",
    "                and not tensordict['observation', 'masks', 'o'][o_idx] \\\n",
    "                and not tensordict['observation', 'masks', 'c'][c_idx] \\\n",
    "                and (o_idx not in assigned_o_idxs) and (c_idx not in assigned_c_idxs) \\\n",
    "            :\n",
    "                assignment = (tensordict['observation', 'ids', 'o'][o_idx].item(), tensordict['observation', 'ids', 'c'][c_idx].item())\n",
    "                assignments.append(assignment)\n",
    "                assigned_o_idxs.add(o_idx)\n",
    "                assigned_c_idxs.add(c_idx)\n",
    "\n",
    "        # print(assignments)\n",
    "        # print(self.simulator.GetState())\n",
    "        self.simulator.Next(assignments)\n",
    "        triple = self.simulator.GetState()\n",
    "        self.model.encode_input(triple, 0)\n",
    "\n",
    "        out = TensorDict(\n",
    "            {\n",
    "                \"next\": {\n",
    "                    \"observation\": {\n",
    "                        'tensors': {\n",
    "                            'o': self.model.tensors['o'],\n",
    "                            'c': self.model.tensors['c'],\n",
    "                            'ar': self.model.tensors['ar']     \n",
    "                        },\n",
    "                        'masks': {\n",
    "                            'o': self.model.masks['o'],\n",
    "                            'c': self.model.masks['c'],\n",
    "                            'ar': self.model.masks['ar']     \n",
    "                        },\n",
    "                        'ids': {\n",
    "                            'o': self.model.ids['o'],\n",
    "                            'c': self.model.ids['c'],\n",
    "                            'ar': self.model.ids['ar']\n",
    "                        }\n",
    "                    },\n",
    "                    \"reward\": torch.tensor(0, dtype=torch.float32),\n",
    "                    \"done\": torch.tensor(False, dtype=torch.bool),\n",
    "                    # \"reward\": torch.tensor([0] * sub_batch_size, dtype=torch.float32),\n",
    "                    # \"done\": torch.tensor([False] * sub_batch_size, dtype=torch.bool),\n",
    "                }\n",
    "            },\n",
    "            tensordict.shape\n",
    "            # batch_size=tensordict.shape[0]\n",
    "        )\n",
    "        # print(out['next', 'observation', 'ids', 'o'])\n",
    "        return out\n",
    "    \n",
    "    def _reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        if tensordict is None or tensordict.is_empty():\n",
    "            return TensorDict(\n",
    "            {\n",
    "                \"observation\": {\n",
    "                    'tensors': {\n",
    "                        'o': self.model.tensors['o'],\n",
    "                        'c': self.model.tensors['c'],\n",
    "                        'ar': self.model.tensors['ar']     \n",
    "                    },\n",
    "                    'masks': {\n",
    "                        'o': self.model.masks['o'],\n",
    "                        'c': self.model.masks['c'],\n",
    "                        'ar': self.model.masks['ar']     \n",
    "                    },\n",
    "                    'ids': {\n",
    "                        'o': self.model.ids['o'],\n",
    "                        'c': self.model.ids['c'],\n",
    "                        'ar': self.model.ids['ar']\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            # batch_size=[sub_batch_size]\n",
    "            batch_size=self.batch_size\n",
    "        ) \n",
    "        return tensordict\n",
    "    \n",
    "    def _set_seed(self, seed: Optional[int]):\n",
    "        rng = torch.manual_seed(seed)\n",
    "        self.rng = rng\n",
    "\n",
    "    def _make_specs(self) -> None:\n",
    "        self.action_spec = DiscreteTensorSpec(\n",
    "            n=MAX_COURIERS,\n",
    "            dtype=torch.int,\n",
    "            shape=self.model.masks['o'].shape\n",
    "        )\n",
    "        observation_spec = CompositeSpec(\n",
    "            tensors = CompositeSpec(\n",
    "                o = UnboundedContinuousTensorSpec(\n",
    "                    shape=self.model.tensors['o'].shape,\n",
    "                    dtype=torch.float\n",
    "                ),\n",
    "                c = UnboundedContinuousTensorSpec(\n",
    "                    shape=self.model.tensors['c'].shape,\n",
    "                    dtype=torch.float\n",
    "                ),\n",
    "                ar = UnboundedContinuousTensorSpec(\n",
    "                    shape=self.model.tensors['ar'].shape,\n",
    "                    dtype=torch.float\n",
    "                ),\n",
    "                # shape=[sub_batch_size]\n",
    "            ),\n",
    "            masks = CompositeSpec(\n",
    "                o = DiscreteTensorSpec(\n",
    "                    n=2,\n",
    "                    dtype=torch.bool,\n",
    "                    shape=self.model.masks['o'].shape\n",
    "                ),\n",
    "                c = DiscreteTensorSpec(\n",
    "                    n=2,\n",
    "                    dtype=torch.bool,\n",
    "                    shape=self.model.masks['c'].shape\n",
    "                ),\n",
    "                ar = DiscreteTensorSpec(\n",
    "                    n=2,\n",
    "                    dtype=torch.bool,\n",
    "                    shape=self.model.masks['ar'].shape\n",
    "                ),\n",
    "                # shape=[sub_batch_size]\n",
    "            ),\n",
    "            ids = CompositeSpec(\n",
    "                o = UnboundedDiscreteTensorSpec(\n",
    "                    dtype=torch.int,\n",
    "                    shape=self.model.ids['o'].shape\n",
    "                ),\n",
    "                c = UnboundedDiscreteTensorSpec(\n",
    "                    dtype=torch.int,\n",
    "                    shape=self.model.ids['c'].shape\n",
    "                ),\n",
    "                ar = UnboundedDiscreteTensorSpec(\n",
    "                    dtype=torch.int,\n",
    "                    shape=self.model.ids['ar'].shape\n",
    "                ),\n",
    "                # shape=[sub_batch_size]\n",
    "            ), \n",
    "            # shape=[sub_batch_size]\n",
    "        )\n",
    "        # if not isinstance(observation_spec, CompositeSpec):\n",
    "        observation_spec = CompositeSpec(observation=observation_spec) # shape=[sub_batch_size]\n",
    "            \n",
    "        self.observation_spec = observation_spec\n",
    "        self.reward_spec = UnboundedContinuousTensorSpec(\n",
    "            # shape=[sub_batch_size],\n",
    "            shape=[1],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.done_spec = BinaryDiscreteTensorSpec(\n",
    "            # n=sub_batch_size,\n",
    "            # shape=[sub_batch_size],\n",
    "            n=1,\n",
    "            shape=[1],\n",
    "            dtype=torch.bool\n",
    "        )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_env = SimulatorEnv(Simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "    my_env,\n",
    "    # Compose(\n",
    "    #     # normalize observations\n",
    "    #     # ObservationNorm(in_keys=[\"observation\"]),\n",
    "    #     # DoubleToFloat(in_keys=[\"observation\"]),\n",
    "    #     StepCounter(),\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    observation: CompositeSpec(\n",
      "        tensors: CompositeSpec(\n",
      "            o: UnboundedContinuousTensorSpec(\n",
      "                 shape=torch.Size([4, 512]), space=None, device=cpu, dtype=torch.float32, domain=continuous),\n",
      "            c: UnboundedContinuousTensorSpec(\n",
      "                 shape=torch.Size([21, 512]), space=None, device=cpu, dtype=torch.float32, domain=continuous),\n",
      "            ar: UnboundedContinuousTensorSpec(\n",
      "                 shape=torch.Size([1, 512]), space=None, device=cpu, dtype=torch.float32, domain=continuous), device=cpu, shape=torch.Size([])),\n",
      "        masks: CompositeSpec(\n",
      "            o: DiscreteTensorSpec(\n",
      "                 shape=torch.Size([4]), space=DiscreteBox(n=2), device=cpu, dtype=torch.bool, domain=discrete),\n",
      "            c: DiscreteTensorSpec(\n",
      "                 shape=torch.Size([21]), space=DiscreteBox(n=2), device=cpu, dtype=torch.bool, domain=discrete),\n",
      "            ar: DiscreteTensorSpec(\n",
      "                 shape=torch.Size([1]), space=DiscreteBox(n=2), device=cpu, dtype=torch.bool, domain=discrete), device=cpu, shape=torch.Size([])),\n",
      "        ids: CompositeSpec(\n",
      "            o: UnboundedDiscreteTensorSpec(\n",
      "                 shape=torch.Size([4]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous),\n",
      "            c: UnboundedDiscreteTensorSpec(\n",
      "                 shape=torch.Size([21]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([21]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([21]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous),\n",
      "            ar: UnboundedDiscreteTensorSpec(\n",
      "                 shape=torch.Size([1]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "     shape=torch.Size([1]), space=None, device=cpu, dtype=torch.float32, domain=continuous)\n",
      "input_spec: CompositeSpec(\n",
      "    action: DiscreteTensorSpec(\n",
      "         shape=torch.Size([4]), space=DiscreteBox(n=50), device=cpu, dtype=torch.int32, domain=discrete), device=cpu, shape=torch.Size([]))\n",
      "action_spec (as defined by input_spec): DiscreteTensorSpec(\n",
      "     shape=torch.Size([4]), space=DiscreteBox(n=50), device=cpu, dtype=torch.int32, domain=discrete)\n"
     ]
    }
   ],
   "source": [
    "# env.transform[0].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)\n",
    "# print(\"normalization constant shape:\", env.transform[0].loc.shape)\n",
    "print(\"observation_spec:\", my_env.observation_spec)\n",
    "print(\"reward_spec:\", my_env.reward_spec)\n",
    "print(\"input_spec:\", my_env.input_spec)\n",
    "print(\"action_spec (as defined by input_spec):\", my_env.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_env_specs(my_env, return_contiguous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "WARNING!\n",
      "\n",
      "c_idx increases MAX_LIMIT\n",
      "Shape of the rollout TensorDict: torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollout = my_env.rollout(10, return_contiguous=False)\n",
    "# print(\"rollout of three steps:\", rollout)\n",
    "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)\n",
    "rollout.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found more than one unique shape in the tensors to be stacked ({torch.Size([6]), torch.Size([8]), torch.Size([4]), torch.Size([7]), torch.Size([10]), torch.Size([3]), torch.Size([9])}). This is likely due to a modification of one of the stacked TensorDicts, where a key has been updated/created with an uncompatible shape. If the entries are intended to have a different shape, use the get_nestedtensor method instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:4859\u001b[0m, in \u001b[0;36mLazyStackedTensorDict.get\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m   4858\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 4859\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(tensors, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_dim)\n\u001b[1;32m   4860\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3] at entry 0 and [4] at entry 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/formatters.py:707\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m stream \u001b[39m=\u001b[39m StringIO()\n\u001b[1;32m    701\u001b[0m printer \u001b[39m=\u001b[39m pretty\u001b[39m.\u001b[39mRepresentationPrinter(stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnewline,\n\u001b[1;32m    703\u001b[0m     max_seq_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_length,\n\u001b[1;32m    704\u001b[0m     singleton_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingleton_printers,\n\u001b[1;32m    705\u001b[0m     type_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_printers,\n\u001b[1;32m    706\u001b[0m     deferred_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 707\u001b[0m printer\u001b[39m.\u001b[39;49mpretty(obj)\n\u001b[1;32m    708\u001b[0m printer\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    709\u001b[0m \u001b[39mreturn\u001b[39;00m stream\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[39mreturn\u001b[39;00m meth(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[39mand\u001b[39;00m callable(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[39mreturn\u001b[39;00m _repr_pprint(obj, \u001b[39mself\u001b[39;49m, cycle)\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_pprint(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39;49m(obj)\n\u001b[1;32m    779\u001b[0m lines \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m p\u001b[39m.\u001b[39mgroup():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2313\u001b[0m, in \u001b[0;36mTensorDictBase.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m-> 2313\u001b[0m     fields \u001b[39m=\u001b[39m _td_fields(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   2314\u001b[0m     field_str \u001b[39m=\u001b[39m indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfields=\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mfields\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2315\u001b[0m     batch_size_str \u001b[39m=\u001b[39m indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch_size=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6012\u001b[0m, in \u001b[0;36m_td_fields\u001b[0;34m(td)\u001b[0m\n\u001b[1;32m   6009\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_td_fields\u001b[39m(td: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6010\u001b[0m     \u001b[39mreturn\u001b[39;00m indent(\n\u001b[1;32m   6011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 6012\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m([_make_repr(key, item, td) \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m td\u001b[39m.\u001b[39mitems()])),\n\u001b[1;32m   6013\u001b[0m         \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   6014\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6012\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6009\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_td_fields\u001b[39m(td: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6010\u001b[0m     \u001b[39mreturn\u001b[39;00m indent(\n\u001b[1;32m   6011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 6012\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m([_make_repr(key, item, td) \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m td\u001b[39m.\u001b[39mitems()])),\n\u001b[1;32m   6013\u001b[0m         \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   6014\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6005\u001b[0m, in \u001b[0;36m_make_repr\u001b[0;34m(key, item, tensordict)\u001b[0m\n\u001b[1;32m   6003\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_repr\u001b[39m(key: \u001b[39mstr\u001b[39m, item: CompatibleType, tensordict: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6004\u001b[0m     \u001b[39mif\u001b[39;00m is_tensor_collection(\u001b[39mtype\u001b[39m(item)):\n\u001b[0;32m-> 6005\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(tensordict\u001b[39m.\u001b[39mget(key))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6006\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m_get_repr(item)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2313\u001b[0m, in \u001b[0;36mTensorDictBase.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m-> 2313\u001b[0m     fields \u001b[39m=\u001b[39m _td_fields(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   2314\u001b[0m     field_str \u001b[39m=\u001b[39m indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfields=\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mfields\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2315\u001b[0m     batch_size_str \u001b[39m=\u001b[39m indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch_size=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6012\u001b[0m, in \u001b[0;36m_td_fields\u001b[0;34m(td)\u001b[0m\n\u001b[1;32m   6009\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_td_fields\u001b[39m(td: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6010\u001b[0m     \u001b[39mreturn\u001b[39;00m indent(\n\u001b[1;32m   6011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 6012\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m([_make_repr(key, item, td) \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m td\u001b[39m.\u001b[39mitems()])),\n\u001b[1;32m   6013\u001b[0m         \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   6014\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6012\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6009\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_td_fields\u001b[39m(td: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6010\u001b[0m     \u001b[39mreturn\u001b[39;00m indent(\n\u001b[1;32m   6011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 6012\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m([_make_repr(key, item, td) \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m td\u001b[39m.\u001b[39mitems()])),\n\u001b[1;32m   6013\u001b[0m         \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   6014\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6005\u001b[0m, in \u001b[0;36m_make_repr\u001b[0;34m(key, item, tensordict)\u001b[0m\n\u001b[1;32m   6003\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_repr\u001b[39m(key: \u001b[39mstr\u001b[39m, item: CompatibleType, tensordict: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6004\u001b[0m     \u001b[39mif\u001b[39;00m is_tensor_collection(\u001b[39mtype\u001b[39m(item)):\n\u001b[0;32m-> 6005\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(tensordict\u001b[39m.\u001b[39mget(key))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6006\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m_get_repr(item)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2313\u001b[0m, in \u001b[0;36mTensorDictBase.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m-> 2313\u001b[0m     fields \u001b[39m=\u001b[39m _td_fields(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   2314\u001b[0m     field_str \u001b[39m=\u001b[39m indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfields=\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mfields\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2315\u001b[0m     batch_size_str \u001b[39m=\u001b[39m indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch_size=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6012\u001b[0m, in \u001b[0;36m_td_fields\u001b[0;34m(td)\u001b[0m\n\u001b[1;32m   6009\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_td_fields\u001b[39m(td: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6010\u001b[0m     \u001b[39mreturn\u001b[39;00m indent(\n\u001b[1;32m   6011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 6012\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m([_make_repr(key, item, td) \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m td\u001b[39m.\u001b[39mitems()])),\n\u001b[1;32m   6013\u001b[0m         \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   6014\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6012\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6009\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_td_fields\u001b[39m(td: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6010\u001b[0m     \u001b[39mreturn\u001b[39;00m indent(\n\u001b[1;32m   6011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 6012\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m([_make_repr(key, item, td) \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m td\u001b[39m.\u001b[39mitems()])),\n\u001b[1;32m   6013\u001b[0m         \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   6014\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6005\u001b[0m, in \u001b[0;36m_make_repr\u001b[0;34m(key, item, tensordict)\u001b[0m\n\u001b[1;32m   6003\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_repr\u001b[39m(key: \u001b[39mstr\u001b[39m, item: CompatibleType, tensordict: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6004\u001b[0m     \u001b[39mif\u001b[39;00m is_tensor_collection(\u001b[39mtype\u001b[39m(item)):\n\u001b[0;32m-> 6005\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(tensordict\u001b[39m.\u001b[39mget(key))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   6006\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m_get_repr(item)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2313\u001b[0m, in \u001b[0;36mTensorDictBase.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__repr__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m-> 2313\u001b[0m     fields \u001b[39m=\u001b[39m _td_fields(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   2314\u001b[0m     field_str \u001b[39m=\u001b[39m indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfields=\u001b[39m\u001b[39m{{\u001b[39;00m\u001b[39m{\u001b[39;00mfields\u001b[39m}\u001b[39;00m\u001b[39m}}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2315\u001b[0m     batch_size_str \u001b[39m=\u001b[39m indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch_size=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6012\u001b[0m, in \u001b[0;36m_td_fields\u001b[0;34m(td)\u001b[0m\n\u001b[1;32m   6009\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_td_fields\u001b[39m(td: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6010\u001b[0m     \u001b[39mreturn\u001b[39;00m indent(\n\u001b[1;32m   6011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 6012\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m([_make_repr(key, item, td) \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m td\u001b[39m.\u001b[39mitems()])),\n\u001b[1;32m   6013\u001b[0m         \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   6014\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:6012\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6009\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_td_fields\u001b[39m(td: TensorDictBase) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m   6010\u001b[0m     \u001b[39mreturn\u001b[39;00m indent(\n\u001b[1;32m   6011\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 6012\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39msorted\u001b[39m([_make_repr(key, item, td) \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m td\u001b[39m.\u001b[39mitems()])),\n\u001b[1;32m   6013\u001b[0m         \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   6014\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:1351\u001b[0m, in \u001b[0;36mTensorDictBase.items\u001b[0;34m(self, include_nested, leaves_only)\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[39m\"\"\"Returns a generator of key-value pairs for the tensordict.\"\"\"\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys(include_nested\u001b[39m=\u001b[39minclude_nested, leaves_only\u001b[39m=\u001b[39mleaves_only):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[39myield\u001b[39;00m k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(k)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:4863\u001b[0m, in \u001b[0;36mLazyStackedTensorDict.get\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m   4861\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstack expects each tensor to be equal size\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n\u001b[1;32m   4862\u001b[0m     shapes \u001b[39m=\u001b[39m {_shape(tensor) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors}\n\u001b[0;32m-> 4863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   4864\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFound more than one unique shape in the tensors to be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4865\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstacked (\u001b[39m\u001b[39m{\u001b[39;00mshapes\u001b[39m}\u001b[39;00m\u001b[39m). This is likely due to a modification \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4866\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof one of the stacked TensorDicts, where a key has been \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4867\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mupdated/created with an uncompatible shape. If the entries \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4868\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mare intended to have a different shape, use the get_nestedtensor \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4869\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmethod instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4870\u001b[0m     )\n\u001b[1;32m   4871\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4872\u001b[0m     \u001b[39mraise\u001b[39;00m err\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found more than one unique shape in the tensors to be stacked ({torch.Size([6]), torch.Size([8]), torch.Size([4]), torch.Size([7]), torch.Size([10]), torch.Size([3]), torch.Size([9])}). This is likely due to a modification of one of the stacked TensorDicts, where a key has been updated/created with an uncompatible shape. If the entries are intended to have a different shape, use the get_nestedtensor method instead."
     ]
    }
   ],
   "source": [
    "rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = TensorDictModule(\n",
    "    net, in_keys=[('observation', 'tensors'), ('observation', 'masks')], out_keys=['logits', 'values']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td = my_env.reset()\n",
    "# net(td['observation', 'tensors'].to_dict(), td['observation', 'masks'].to_dict())\n",
    "# td['observation', 'tensors'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running policy: torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(\"Running policy:\", module(my_env.reset()).shape)\n",
    "# env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [0, 1, 2, 3]:\n",
    "#     print(my_env.simulators[i].GetMetrics())\n",
    "#     print('-'* 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensordict.nn.distributions import Categorical\n",
    "from torch.distributions.categorical import Categorical\n",
    "policy_module_actor = ProbabilisticActor(\n",
    "    module=module,\n",
    "    in_keys=[\"logits\"],\n",
    "    distribution_class=Categorical,\n",
    "    # distribution_kwargs={\n",
    "    #     \"n\": env.action_spec.space.n,\n",
    "    # },\n",
    "    return_log_prob=True,\n",
    "    # we'll need the log-prob for the numerator of the importance weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogPolicyAvg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, mask):\n",
    "        assert (len(input.shape) == 2 and len(mask.shape) == 2) or (len(input.shape) == 1 and len(mask.shape) == 1), 'dims should be [bs, ord] or [ord]'\n",
    "\n",
    "        sums = torch.sum(torch.where(mask, input, 0), dim=-1)\n",
    "        nums = torch.sum(torch.where(mask, 1, 0), dim=-1)\n",
    "\n",
    "        return torch.where(nums > 0, sums / nums, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
    "final_module = TensorDictSequential(\n",
    "    policy_module_actor,\n",
    "    TensorDictModule(LogPolicyAvg(), in_keys=['sample_log_prob', ('observation', 'masks', 'o')], out_keys=['sample_log_prob']),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_module = ValueOperator(\n",
    "#     module=net,\n",
    "#     in_keys=[('observation', 'tensors'), ('observation', 'masks')], \n",
    "#     out_keys=['logits', 'values']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    my_env,\n",
    "    policy_module_actor,\n",
    "    frames_per_batch=1,\n",
    "    total_frames=5,\n",
    "    split_trajs=False,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (4) must match the existing size (18) at non-singleton dimension 0.  Target sizes: [4, 512].  Tensor sizes: [18, 512]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchrl/collectors/collectors.py:691\u001b[0m, in \u001b[0;36mSyncDataCollector.rollout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensordict_out[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, j] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict\n\u001b[1;32m    692\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     \u001b[39m# unlock the output tensordict to allow for new keys to be written\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[39m# these will be missed during the sync but at least we won't get an error during the update\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2636\u001b[0m, in \u001b[0;36mTensorDictBase.__setitem__\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m keys:\n\u001b[0;32m-> 2636\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_at_(key, item, index)\n\u001b[1;32m   2637\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:3212\u001b[0m, in \u001b[0;36mTensorDict.set_at_\u001b[0;34m(self, key, value, idx)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3212\u001b[0m     _set_item(tensor_in, idx, value)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/utils.py:664\u001b[0m, in \u001b[0;36m_set_item\u001b[0;34m(tensor, index, value)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 664\u001b[0m     tensor[index] \u001b[39m=\u001b[39m value\n\u001b[1;32m    665\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2636\u001b[0m, in \u001b[0;36mTensorDictBase.__setitem__\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m keys:\n\u001b[0;32m-> 2636\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_at_(key, item, index)\n\u001b[1;32m   2637\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:3212\u001b[0m, in \u001b[0;36mTensorDict.set_at_\u001b[0;34m(self, key, value, idx)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3212\u001b[0m     _set_item(tensor_in, idx, value)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/utils.py:664\u001b[0m, in \u001b[0;36m_set_item\u001b[0;34m(tensor, index, value)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 664\u001b[0m     tensor[index] \u001b[39m=\u001b[39m value\n\u001b[1;32m    665\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2636\u001b[0m, in \u001b[0;36mTensorDictBase.__setitem__\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m keys:\n\u001b[0;32m-> 2636\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_at_(key, item, index)\n\u001b[1;32m   2637\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:3212\u001b[0m, in \u001b[0;36mTensorDict.set_at_\u001b[0;34m(self, key, value, idx)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3212\u001b[0m     _set_item(tensor_in, idx, value)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/utils.py:658\u001b[0m, in \u001b[0;36m_set_item\u001b[0;34m(tensor, index, value)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 658\u001b[0m     tensor[index] \u001b[39m=\u001b[39m value\n\u001b[1;32m    659\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (18) at non-singleton dimension 0.  Target sizes: [4, 512].  Tensor sizes: [18, 512]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb Cell 25\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, c \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(collector):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchrl/collectors/collectors.py:596\u001b[0m, in \u001b[0;36mSyncDataCollector.iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    594\u001b[0m i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    595\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter \u001b[39m=\u001b[39m i\n\u001b[0;32m--> 596\u001b[0m tensordict_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout()\n\u001b[1;32m    597\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_frames \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tensordict_out\u001b[39m.\u001b[39mnumel()\n\u001b[1;32m    598\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_frames \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m total_frames:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchrl/_utils.py:296\u001b[0m, in \u001b[0;36maccept_remote_rref_invocation.<locals>.unpack_rref_and_invoke_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _os_is_windows \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_distributed_rpc\u001b[39m.\u001b[39mPyRRef):\n\u001b[1;32m    295\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_value()\n\u001b[0;32m--> 296\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchrl/collectors/collectors.py:697\u001b[0m, in \u001b[0;36mSyncDataCollector.rollout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    695\u001b[0m is_shared \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict_out\u001b[39m.\u001b[39mis_shared()\n\u001b[1;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict_out\u001b[39m.\u001b[39munlock_()\n\u001b[0;32m--> 697\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensordict_out[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, j] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict\n\u001b[1;32m    698\u001b[0m \u001b[39mif\u001b[39;00m is_shared:\n\u001b[1;32m    699\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict_out\u001b[39m.\u001b[39mshare_memory_()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2636\u001b[0m, in \u001b[0;36mTensorDictBase.__setitem__\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m   2634\u001b[0m \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m value\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2635\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m keys:\n\u001b[0;32m-> 2636\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_at_(key, item, index)\n\u001b[1;32m   2637\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2638\u001b[0m         subtd\u001b[39m.\u001b[39mset(key, item)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:3212\u001b[0m, in \u001b[0;36mTensorDict.set_at_\u001b[0;34m(self, key, value, idx)\u001b[0m\n\u001b[1;32m   3210\u001b[0m     tensor_in\u001b[39m.\u001b[39mcopy_(value)\n\u001b[1;32m   3211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3212\u001b[0m     _set_item(tensor_in, idx, value)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/utils.py:664\u001b[0m, in \u001b[0;36m_set_item\u001b[0;34m(tensor, index, value)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n\u001b[1;32m    663\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 664\u001b[0m     tensor[index] \u001b[39m=\u001b[39m value\n\u001b[1;32m    665\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2636\u001b[0m, in \u001b[0;36mTensorDictBase.__setitem__\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m   2634\u001b[0m \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m value\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2635\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m keys:\n\u001b[0;32m-> 2636\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_at_(key, item, index)\n\u001b[1;32m   2637\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2638\u001b[0m         subtd\u001b[39m.\u001b[39mset(key, item)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:3212\u001b[0m, in \u001b[0;36mTensorDict.set_at_\u001b[0;34m(self, key, value, idx)\u001b[0m\n\u001b[1;32m   3210\u001b[0m     tensor_in\u001b[39m.\u001b[39mcopy_(value)\n\u001b[1;32m   3211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3212\u001b[0m     _set_item(tensor_in, idx, value)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/utils.py:664\u001b[0m, in \u001b[0;36m_set_item\u001b[0;34m(tensor, index, value)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n\u001b[1;32m    663\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 664\u001b[0m     tensor[index] \u001b[39m=\u001b[39m value\n\u001b[1;32m    665\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:2636\u001b[0m, in \u001b[0;36mTensorDictBase.__setitem__\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m   2634\u001b[0m \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m value\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2635\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m keys:\n\u001b[0;32m-> 2636\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_at_(key, item, index)\n\u001b[1;32m   2637\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2638\u001b[0m         subtd\u001b[39m.\u001b[39mset(key, item)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/tensordict.py:3212\u001b[0m, in \u001b[0;36mTensorDict.set_at_\u001b[0;34m(self, key, value, idx)\u001b[0m\n\u001b[1;32m   3210\u001b[0m     tensor_in\u001b[39m.\u001b[39mcopy_(value)\n\u001b[1;32m   3211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3212\u001b[0m     _set_item(tensor_in, idx, value)\n\u001b[1;32m   3214\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/tensordict/utils.py:658\u001b[0m, in \u001b[0;36m_set_item\u001b[0;34m(tensor, index, value)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\n\u001b[1;32m    655\u001b[0m     tensor: torch\u001b[39m.\u001b[39mTensor, index: IndexType, value: torch\u001b[39m.\u001b[39mTensor\n\u001b[1;32m    656\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    657\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 658\u001b[0m         tensor[index] \u001b[39m=\u001b[39m value\n\u001b[1;32m    659\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\n\u001b[1;32m    660\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, KeyedJaggedTensor):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (4) must match the existing size (18) at non-singleton dimension 0.  Target sizes: [4, 512].  Tensor sizes: [18, 512]"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(collector):\n",
    "    if i == 1:\n",
    "        break\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import ReplayBuffer, LazyTensorStorage\n",
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(frames_per_batch),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=sub_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_module = GAE(\n",
    "    gamma=gamma, lmbda=lmbda, value_network=module, average_gae=True, value_key='values'\n",
    ")\n",
    "\n",
    "loss_module = ClipPPOLoss(\n",
    "    actor=policy_module_actor,\n",
    "    critic=final_module,\n",
    "    advantage_key=\"advantage\",\n",
    "    clip_epsilon=clip_epsilon,\n",
    "    entropy_bonus=bool(entropy_eps),\n",
    "    entropy_coef=entropy_eps,\n",
    "    # these keys match by default but we set this for completeness\n",
    "    value_target_key=advantage_module.value_target_key,\n",
    "    critic_coef=1.0,\n",
    "    gamma=0.99,\n",
    "    loss_critic_type=\"smooth_l1\",\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(loss_module.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(collector):\n",
    "    if i == 5:\n",
    "        break\n",
    "    advantage_module(c)\n",
    "    data_view = c.reshape(-1)\n",
    "    replay_buffer.extend(data_view.cpu())\n",
    "\n",
    "subdata = replay_buffer.sample()\n",
    "# loss_vals = loss_module(subdata)\n",
    "# loss_value = (\n",
    "#     loss_vals[\"loss_objective\"]\n",
    "#     + loss_vals[\"loss_critic\"]\n",
    "#     + loss_vals[\"loss_entropy\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        advantage: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        collector.traj_ids: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        logits: Tensor(shape=torch.Size([4, 1, 22]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.done: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.ids.ar: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.ids.c: Tensor(shape=torch.Size([4, 21]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.ids.o: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.masks.ar: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.masks.c: Tensor(shape=torch.Size([4, 21]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.masks.o: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.tensors.ar: Tensor(shape=torch.Size([4, 1, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.observation.tensors.c: Tensor(shape=torch.Size([4, 21, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.observation.tensors.o: Tensor(shape=torch.Size([4, 1, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.reward: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.ids.ar: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.ids.c: Tensor(shape=torch.Size([4, 21]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.ids.o: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.masks.ar: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.masks.c: Tensor(shape=torch.Size([4, 21]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.masks.o: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.tensors.ar: Tensor(shape=torch.Size([4, 1, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.tensors.c: Tensor(shape=torch.Size([4, 21, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.tensors.o: Tensor(shape=torch.Size([4, 1, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        sample_log_prob: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        value_target: Tensor(shape=torch.Size([4, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        values: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([4]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdata.flatten_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "advantage.shape and log_weight.shape do not match (got torch.Size([4, 1]) and torch.Size([4, 1, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb Cell 30\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m loss_vals \u001b[39m=\u001b[39m loss_module(subdata)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchrl/objectives/ppo.py:244\u001b[0m, in \u001b[0;36mClipPPOLoss.forward\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    241\u001b[0m     batch \u001b[39m=\u001b[39m log_weight\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m advantage\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m log_weight\u001b[39m.\u001b[39mshape:\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    245\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madvantage.shape and log_weight.shape do not match (got \u001b[39m\u001b[39m{\u001b[39;00madvantage\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand \u001b[39m\u001b[39m{\u001b[39;00mlog_weight\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    248\u001b[0m gain1 \u001b[39m=\u001b[39m log_weight\u001b[39m.\u001b[39mexp() \u001b[39m*\u001b[39m advantage\n\u001b[1;32m    250\u001b[0m log_weight_clip \u001b[39m=\u001b[39m log_weight\u001b[39m.\u001b[39mclamp(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clip_bounds)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: advantage.shape and log_weight.shape do not match (got torch.Size([4, 1]) and torch.Size([4, 1, 1]))"
     ]
    }
   ],
   "source": [
    "loss_vals = loss_module(subdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=total_frames * frame_skip)\n",
    "eval_str = \"\"\n",
    "\n",
    "# We iterate over the collector until it reaches the total number of frames it was\n",
    "# designed to collect:\n",
    "for i, tensordict_data in enumerate(collector):\n",
    "    # we now have a batch of data to work with. Let's learn something from it.\n",
    "    for _ in range(num_epochs):\n",
    "        # We'll need an \"advantage\" signal to make PPO work.\n",
    "        # We re-compute it at each epoch as its value depends on the value\n",
    "        # network which is updated in the inner loop.\n",
    "        advantage_module(tensordict_data)\n",
    "        data_view = tensordict_data.reshape(-1)\n",
    "        replay_buffer.extend(data_view.cpu())\n",
    "        for _ in range(frames_per_batch // sub_batch_size):\n",
    "            subdata = replay_buffer.sample(sub_batch_size)\n",
    "            loss_vals = loss_module(subdata.to(device))\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            # Optimization: backward, grad clipping and optim step\n",
    "            loss_value.backward()\n",
    "            # this is not strictly mandatory but it's good practice to keep\n",
    "            # your gradient norm bounded\n",
    "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "\n",
    "class TestEnv(EnvBase):\n",
    "    def __init__(self, seed=None, device=\"cpu\"):\n",
    "        super().__init__(device=device, batch_size=[bs])\n",
    "        self._make_specs()\n",
    "        \n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.long).random_().item()\n",
    "        self.set_seed(seed)\n",
    "        \n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        '''\n",
    "        tensordict['action'] - a np.array of indexes of couriers assigned for the given order. If there is no courier assigned -1 is provided.\n",
    "        '''\n",
    "        print('next')\n",
    "        out = TensorDict(\n",
    "            {\n",
    "                \"next\": {\n",
    "                    \"observation\": TensorDict({\n",
    "                        'a': torch.tensor([[-1, -2], [-4, -5]], dtype=torch.float),\n",
    "                        'b': torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float),\n",
    "                        },\n",
    "                        batch_size=[bs]\n",
    "                    ),\n",
    "                    \"reward\": torch.tensor([0] * bs, dtype=torch.float32),\n",
    "                    \"done\": torch.tensor([False] * bs, dtype=torch.bool),\n",
    "                }\n",
    "            },\n",
    "            batch_size=[bs]\n",
    "        )\n",
    "        return out\n",
    "    \n",
    "    def _reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        if tensordict is None or tensordict.is_empty():\n",
    "            return TensorDict(\n",
    "            {\n",
    "                \"observation\": TensorDict({\n",
    "                        'a': torch.tensor([[-1, -2], [-4, -5]], dtype=torch.float),\n",
    "                        'b': torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float),\n",
    "                        },\n",
    "                        batch_size=[bs]\n",
    "                    ),\n",
    "            },\n",
    "            batch_size=[bs]\n",
    "        ) \n",
    "        return tensordict\n",
    "    \n",
    "    def _set_seed(self, seed: Optional[int]):\n",
    "        rng = torch.manual_seed(seed)\n",
    "        self.rng = rng\n",
    "\n",
    "    def _make_specs(self) -> None:\n",
    "        self.action_spec = UnboundedDiscreteTensorSpec(\n",
    "            dtype=torch.int,\n",
    "            shape=[bs]\n",
    "            # shape=(1,)\n",
    "            # shape=(self.model.tensors['o'].shape[0],)\n",
    "        )\n",
    "        observation_spec = CompositeSpec(\n",
    "            a = UnboundedContinuousTensorSpec(\n",
    "                dtype=torch.float32,\n",
    "                shape=[bs]\n",
    "            ),\n",
    "            b = UnboundedContinuousTensorSpec(\n",
    "                dtype=torch.float32,\n",
    "                shape=[bs]\n",
    "            ),\n",
    "            shape=[bs]\n",
    "        )\n",
    "        # if not isinstance(observation_spec, CompositeSpec):\n",
    "        observation_spec = CompositeSpec(observation=observation_spec, shape=[bs])\n",
    "            \n",
    "        self.observation_spec = observation_spec\n",
    "        self.reward_spec = UnboundedContinuousTensorSpec(\n",
    "            shape=[bs],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.done_spec = BinaryDiscreteTensorSpec(\n",
    "            bs,\n",
    "            shape=[bs]\n",
    "        )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "    TestEnv(),\n",
    "    # Compose(\n",
    "    #     # normalize observations\n",
    "    #     # ObservationNorm(in_keys=[\"observation\"]),\n",
    "    #     # DoubleToFloat(in_keys=[\"observation\"]),\n",
    "    #     StepCounter(),\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    observation: CompositeSpec(\n",
      "        a: UnboundedContinuousTensorSpec(\n",
      "             shape=torch.Size([2, 3]), space=None, device=cpu, dtype=torch.float32, domain=continuous),\n",
      "        b: UnboundedContinuousTensorSpec(\n",
      "             shape=torch.Size([2, 3]), space=None, device=cpu, dtype=torch.float32, domain=continuous), device=cpu, shape=torch.Size([2, 3])), device=cpu, shape=torch.Size([2]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "     shape=torch.Size([2]), space=None, device=cpu, dtype=torch.float32, domain=continuous)\n",
      "input_spec: CompositeSpec(\n",
      "    action: UnboundedDiscreteTensorSpec(\n",
      "         shape=torch.Size([2]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous), device=cpu, shape=torch.Size([2]))\n",
      "action_spec (as defined by input_spec): UnboundedDiscreteTensorSpec(\n",
      "     shape=torch.Size([2]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous)\n",
      "next\n",
      "next\n",
      "next\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The dtypes of the real and fake tensordict don't match for key next.done. Got fake=torch.int64 and real=torch.bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb Cell 17\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minput_spec:\u001b[39m\u001b[39m\"\u001b[39m, env\u001b[39m.\u001b[39minput_spec)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39maction_spec (as defined by input_spec):\u001b[39m\u001b[39m\"\u001b[39m, env\u001b[39m.\u001b[39maction_spec)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m check_env_specs(env)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchrl/envs/utils.py:290\u001b[0m, in \u001b[0;36mcheck_env_specs\u001b[0;34m(env, return_contiguous, check_dtype, seed)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe shapes of the real and fake tensordict don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match for key \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot fake=\u001b[39m\u001b[39m{\u001b[39;00mfake_tensordict[key]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and real=\u001b[39m\u001b[39m{\u001b[39;00mreal_tensordict[key]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         )\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m check_dtype \u001b[39mand\u001b[39;00m (fake_tensordict[key]\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m real_tensordict[key]\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m--> 290\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    291\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe dtypes of the real and fake tensordict don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match for key \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot fake=\u001b[39m\u001b[39m{\u001b[39;00mfake_tensordict[key]\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m and real=\u001b[39m\u001b[39m{\u001b[39;00mreal_tensordict[key]\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         )\n\u001b[1;32m    295\u001b[0m \u001b[39m# test dtypes\u001b[39;00m\n\u001b[1;32m    296\u001b[0m real_tensordict \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mrollout(\u001b[39m3\u001b[39m)  \u001b[39m# keep empty structures, for example dict()\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The dtypes of the real and fake tensordict don't match for key next.done. Got fake=torch.int64 and real=torch.bool."
     ]
    }
   ],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)\n",
    "print(\"input_spec:\", env.input_spec)\n",
    "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
    "\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        next.done: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        next.observation.a: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.observation.b: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.reward: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.a: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.b: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        reward: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([2]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "next\n",
      "next\n",
      "next\n",
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        next.done: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next.observation.a: Tensor(shape=torch.Size([2, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.observation.b: Tensor(shape=torch.Size([2, 3, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.reward: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.a: Tensor(shape=torch.Size([2, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.b: Tensor(shape=torch.Size([2, 3, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        reward: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([2, 3]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "fake = env.fake_tensordict().flatten_keys(\".\")\n",
    "print(fake)\n",
    "\n",
    "real_tensordict = env.rollout(3, return_contiguous=True).flatten_keys(\".\")\n",
    "print(real_tensordict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tensordict = fake.unsqueeze(real_tensordict.batch_dims - 1).expand(*real_tensordict.shape).to_tensordict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        next.done: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        next.observation.a: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.observation.b: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.reward: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.a: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.b: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([2, 3]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real_tensordict.apply(lambda x: torch.zeros_like(x)) == fake_tensordict.apply(lambda x: torch.zeros_like(x))\n",
    "# fake_tensordict\n",
    "fake_tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(3, 5)\n",
    "        self.f2 = nn.Linear(3, 5)\n",
    "\n",
    "        self.last = nn.Linear(5, 2)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = self.f1(x)\n",
    "        y = self.f2(y)\n",
    "\n",
    "        return self.last(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7460, -0.8222]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3]], dtype=torch.float)\n",
    "y = torch.tensor([[1, 2, 3]], dtype=torch.float)\n",
    "n = Net()\n",
    "n(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_module = TensorDictModule(\n",
    "    n, in_keys=[('inp', \"x\"), ('inp', \"y\")], out_keys=[\"out\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_module(x=x, y=y)\n",
    "inp = TensorDict(\n",
    "    {\n",
    "        'inp': TensorDict({\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "        }, batch_size=())\n",
    "    },\n",
    "    batch_size=(1, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = policy_module(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9481, 0.0790], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
