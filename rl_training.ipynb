{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.24.3)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hCollecting gym==0.21.0\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensordict\n",
      "  Downloading tensordict-0.1.2-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.1/130.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchrl\n",
      "  Downloading torchrl-0.1.1-cp310-cp310-manylinux1_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m0m\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.15.7-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (23.0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing<3.1,>=2.3.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 3)) (9.4.0)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 5)) (2022.7)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 10)) (5.9.0)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting protobuf!=4.21.0,<5,>=3.19.0\n",
      "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 10)) (65.6.3)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.28.1-py2.py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 10)) (2.29.0)\n",
      "Collecting Click!=8.0.0,>=7.1\n",
      "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 10)) (6.0)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 10)) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 10)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 10)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 10)) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 10)) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: gym, pathtools\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616797 sha256=64889bb1290fe4ee97ac93cb3b5870ef266a02ba22c97ccc84a73d52966d4beb\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/aa/90/b67df76370d3916a2189b662cf48da38ce41a4e7e58b6abff5\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=13e11d1c936540e2ca7c05bbeccd7c96af6b024c140495a3ca40f8d7a109dc3e\n",
      "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "Successfully built gym pathtools\n",
      "Installing collected packages: pathtools, appdirs, tzdata, smmap, setproctitle, sentry-sdk, scipy, pyparsing, protobuf, kiwisolver, joblib, fonttools, docker-pycreds, cycler, contourpy, cloudpickle, Click, pandas, matplotlib, gym, gitdb, tensordict, GitPython, wandb, torchrl\n",
      "Successfully installed Click-8.1.6 GitPython-3.1.32 appdirs-1.4.4 cloudpickle-2.2.1 contourpy-1.1.0 cycler-0.11.0 docker-pycreds-0.4.0 fonttools-4.41.1 gitdb-4.0.10 gym-0.21.0 joblib-1.3.1 kiwisolver-1.4.4 matplotlib-3.7.2 pandas-2.0.3 pathtools-0.1.2 protobuf-4.23.4 pyparsing-3.0.9 scipy-1.11.1 sentry-sdk-1.28.1 setproctitle-1.3.2 smmap-5.0.0 tensordict-0.1.2 torchrl-0.1.1 tzdata-2023.3 wandb-0.15.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'd:\\msys2\\mingw64\\bin\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'd:/msys2/mingw64/bin/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from src.dispatch.dispatch import NeuralDispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from utils import *\n",
    "from dispatch.dispatch import Dispatch, NeuralDispatch\n",
    "from simulator.base_simulator import BaseSimulator, ManualSimulator\n",
    "from simulator.simulator import Simulator\n",
    "from simulator.graphics import plot_CR, plot_counts\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from networks.encoders.point_encoder import PointEncoder\n",
    "# from networks.scoring_v1 import ScoringNet, ScoringInterface\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "from objects.point import Point\n",
    "from networks.scoring_networks.net1 import ScoringNet\n",
    "from networks.encoders.gamble_encoder import GambleTripleEncoder\n",
    "# from networks.utils import get_assignments_by_scores\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "# import importlib\n",
    "# importlib.reload(networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net weights loaded successfuly!\n",
      "gamble encoder weights loaded successfuly!\n"
     ]
    }
   ],
   "source": [
    "with open('configs/network_hyperparams.json') as f:\n",
    "    hyperparams = json.load(f)    \n",
    "\n",
    "net = ScoringNet(\n",
    "    n_layers=hyperparams['n_layers'],\n",
    "    d_model=hyperparams['d_model'],\n",
    "    n_head=hyperparams['n_head'],\n",
    "    dim_ff=hyperparams['dim_ff'],\n",
    "    device=device,\n",
    "    path_weights='pretrained_models/eta_scoring_1/eta_scoring_1.pt'\n",
    ")\n",
    "\n",
    "# point_encoder = PointEncoder(point_enc_dim=hyperparams['point_enc_dim'], device=device)\n",
    "# point_encoder.load_state_dict(torch.load('pretrained_models/point_encoder64/point_encoder64.pt', map_location=device))\n",
    "\n",
    "encoder = GambleTripleEncoder(\n",
    "    number_enc_dim=hyperparams['number_enc_dim'], \n",
    "    d_model=hyperparams['d_model'], \n",
    "    point_enc_dim=hyperparams['point_enc_dim'],\n",
    "    path_weights='pretrained_models/assignment_cloning_model_v2/encoders/',\n",
    "    # point_encoder=point_encoder,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "bounds = (Point(0, 0), Point(10, 10))\n",
    "# model = ScoringInterface(net)\n",
    "# model.load_weights('pretrained_models/assignment_cloning_model_v2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343967769/work/aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12154696132596685"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from networks.utils import (\n",
    "    get_target_assignments,\n",
    "    get_batch_embeddings_tensors,\n",
    "    get_batch_masks,\n",
    "    cross_entropy_assignment_loss,\n",
    "    get_cross_mask\n",
    ")\n",
    "from utils import get_batch_quality_metrics, get_CR, update_assignment_accuracy_statistics\n",
    "from networks.utils import get_assignments_by_scores\n",
    "\n",
    "with open('configs/training_settings.json') as f:\n",
    "    training_settings = json.load(f)\n",
    "\n",
    "dsp = NeuralDispatch(net, encoder)\n",
    "get_CR(get_batch_quality_metrics(dsp, Simulator, 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"delivery-RL\", \n",
    "    name=f\"increase_max_items\", \n",
    "    config={\n",
    "        'hyperparams': hyperparams,\n",
    "        'training_settings': training_settings,\n",
    "        'device': device,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb Cell 9\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m batch_embs \u001b[39m=\u001b[39m get_batch_embeddings_tensors(embeds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m batch_masks \u001b[39m=\u001b[39m get_batch_masks(triples, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m pred_scores, _ \u001b[39m=\u001b[39m net(batch_embs, batch_masks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# if iter > 20:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m# print('gamble info:\\n')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# for enum, triple in enumerate(triples):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# gradient step\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/optim/optimizer.py:461\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mgrad \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[39mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 461\u001b[0m         p\u001b[39m.\u001b[39mgrad \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m         \u001b[39mif\u001b[39;00m p\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mgrad_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = Counter()\n",
    "num_epochs = training_settings['num_epochs']\n",
    "num_iters = training_settings['num_iters_in_epoch']\n",
    "batch_size = training_settings['batch_size']\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=training_settings['lr'], momentum=training_settings['momentum'])\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-3, epochs=n_epochs, steps_per_epoch=n_iters)\n",
    "scheduler = None\n",
    "\n",
    "def apply_next_to_simulator(idx, simulators, assignments):\n",
    "    simulators[idx].Next(assignments[idx])\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    net.train()\n",
    "    encoder.train()\n",
    "    simulators = [Simulator() for i in range(batch_size)]\n",
    "    for iter in range(num_iters):\n",
    "        triples = [sim.GetState() for sim in simulators]\n",
    "\n",
    "        # triples = [random_triple(bounds, max_items=20) for _ in range(batch_size)]\n",
    "        max_num_ords = max([len(triple.orders) for triple in triples])\n",
    "        max_num_crrs = max([len(triple.couriers) for triple in triples])\n",
    "\n",
    "        target_assignment_idxs = []\n",
    "        embeds = []\n",
    "        ids = []\n",
    "        for triple in triples:\n",
    "            target_assignment_idxs.append(get_target_assignments(triple, max_num_ords, max_num_crrs))\n",
    "            current_embeds, current_ids = encoder(triple, 0)\n",
    "            embeds.append(current_embeds)\n",
    "            ids.append(current_ids)\n",
    "\n",
    "        batch_embs = get_batch_embeddings_tensors(embeds)\n",
    "        batch_masks = get_batch_masks(triples, device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_scores, _ = net(batch_embs, batch_masks)\n",
    "\n",
    "        # if iter > 20:\n",
    "            # print('gamble info:\\n')\n",
    "            # for enum, triple in enumerate(triples):\n",
    "            #     print(f'triple number {enum}:\\n', triple)\n",
    "            #     print('tgt_ass:', target_assignment_idxs[enum])\n",
    "            #     print('pred_assignments\\n', pred_scores[enum, 1:, 1:].argmax(dim=-1))\n",
    "            # print('pred_scores\\n', pred_scores)\n",
    "            # print(pred_scores.shape)\n",
    "            # print('tgt_assignments\\n', target_assignment_idxs)\n",
    "        # print('masks\\n', get_cross_mask(batch_masks))\n",
    "\n",
    "        # gradient step\n",
    "        loss = cross_entropy_assignment_loss(pred_scores, target_assignment_idxs, get_cross_mask(batch_masks))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # interraction\n",
    "        assignments_batch = get_assignments_by_scores(pred_scores, batch_masks, ids)\n",
    "        Parallel(n_jobs=-1)(delayed(apply_next_to_simulator)(i, simulators, assignments_batch) for i in range(batch_size))\n",
    "        # for i in range(batch_size):\n",
    "        #     simulators[i].Next(assignments_batch[i])\n",
    "            \n",
    "        # get accuracy statistics\n",
    "        for batch_idx in range(batch_size):\n",
    "            update_assignment_accuracy_statistics(target_assignment_idxs[batch_idx], pred_scores[batch_idx], c)\n",
    "        \n",
    "        wandb.log({\"loss\": loss.item()})\n",
    "\n",
    "    dsp = NeuralDispatch(net, encoder)\n",
    "    cr = get_CR(get_batch_quality_metrics(dsp, Simulator, batch_size=training_settings['eval_batch_size'], num_steps=training_settings['eval_num_steps']))\n",
    "    print(cr)\n",
    "    wandb.log({'cr': cr})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "Counter({'not_masked_couriers': 160, 'correct': 152, 'fake_mistake_assigns': 7, 'fake_mistake_not_assigns': 1, 'masked_assigns': 0, 'real_mistakes': 0})\n"
     ]
    }
   ],
   "source": [
    "print(c['fake_mistake_not_assigns'] + c['fake_mistake_assigns'] + c['real_mistakes'] + c['correct'])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2848.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro average CR:  0.7616067567623884\n",
      "macro average CR:  0.7129616821137087\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average free couriers:  2.23\n",
      "average free orders:  11.94\n",
      "average active routes:  17.77\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7023809523809523\n"
     ]
    }
   ],
   "source": [
    "# dsp = NeuralDispatch(net)\n",
    "dsp = Dispatch()\n",
    "sim = Simulator()\n",
    "\n",
    "all_metrics = []\n",
    "for i in tqdm(range(100)):\n",
    "    metrics = sim.GetMetrics()\n",
    "    all_metrics.append(metrics)\n",
    "    state = sim.GetState()\n",
    "    sim.Next(dsp(state))\n",
    "\n",
    "plot_CR(all_metrics)\n",
    "plot_counts(all_metrics)\n",
    "print(get_CR([all_metrics]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n",
      "rollout of three steps: TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next.done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next.observation.ids.ar: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        next.observation.ids.c: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        next.observation.ids.o: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        next.observation.masks.ar: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next.observation.masks.c: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next.observation.masks.o: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next.observation.tensors.ar: Tensor(shape=torch.Size([10, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.observation.tensors.c: Tensor(shape=torch.Size([10, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.observation.tensors.o: Tensor(shape=torch.Size([10, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.ids.ar: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        observation.ids.c: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        observation.ids.o: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        observation.masks.ar: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation.masks.c: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation.masks.o: Tensor(shape=torch.Size([10, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation.tensors.ar: Tensor(shape=torch.Size([10, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.tensors.c: Tensor(shape=torch.Size([10, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.tensors.o: Tensor(shape=torch.Size([10, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "Shape of the rollout TensorDict: torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from reinforcement.simulator_environment import SimulatorEnv\n",
    "from reinforcement.custom_GAE import CustomGAE\n",
    "from simulator.simulator import Simulator\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torchrl.modules import ProbabilisticActor\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import ReplayBuffer, LazyTensorStorage\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.objectives import ClipPPOLoss\n",
    "import json\n",
    "import time\n",
    "\n",
    "with open('configs/rl_settings.json') as f:\n",
    "    rl_settings = json.load(f)\n",
    "    \n",
    "my_env = SimulatorEnv(Simulator)\n",
    "\n",
    "check_env_specs(my_env)\n",
    "\n",
    "rollout = my_env.rollout(10)\n",
    "print(\"rollout of three steps:\", rollout.flatten_keys('.'))\n",
    "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)\n",
    "rollout.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m module \u001b[39m=\u001b[39m TensorDictModule(\n\u001b[1;32m      2\u001b[0m     net, in_keys\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtensors\u001b[39m\u001b[39m'\u001b[39m), (\u001b[39m'\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m'\u001b[39m)], out_keys\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstate_value\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m policy_module_actor \u001b[39m=\u001b[39m ProbabilisticActor(\n\u001b[1;32m      6\u001b[0m     module\u001b[39m=\u001b[39mmodule,\n\u001b[1;32m      7\u001b[0m     in_keys\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m     distribution_class\u001b[39m=\u001b[39mCategorical,\n\u001b[1;32m      9\u001b[0m     return_log_prob\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m collector \u001b[39m=\u001b[39m SyncDataCollector(\n\u001b[1;32m     13\u001b[0m     my_env,\n\u001b[1;32m     14\u001b[0m     policy_module_actor,\n\u001b[1;32m     15\u001b[0m     frames_per_batch\u001b[39m=\u001b[39;49mrl_settings[\u001b[39m'\u001b[39;49m\u001b[39mframes_per_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     16\u001b[0m     total_frames\u001b[39m=\u001b[39;49mrl_settings[\u001b[39m'\u001b[39;49m\u001b[39mtotal_frames\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     17\u001b[0m     split_trajs\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     18\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m replay_buffer \u001b[39m=\u001b[39m ReplayBuffer(\n\u001b[1;32m     22\u001b[0m     storage\u001b[39m=\u001b[39mLazyTensorStorage(rl_settings[\u001b[39m'\u001b[39m\u001b[39mframes_per_epoch\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     23\u001b[0m     sampler\u001b[39m=\u001b[39mSamplerWithoutReplacement(),\n\u001b[1;32m     24\u001b[0m     batch_size\u001b[39m=\u001b[39mrl_settings[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m advantage_module \u001b[39m=\u001b[39m CustomGAE(\n\u001b[1;32m     28\u001b[0m     gamma\u001b[39m=\u001b[39mrl_settings[\u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m], lmbda\u001b[39m=\u001b[39mrl_settings[\u001b[39m'\u001b[39m\u001b[39mlmbda\u001b[39m\u001b[39m'\u001b[39m], value_network\u001b[39m=\u001b[39mmodule, average_gae\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, value_key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstate_value\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     29\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchrl/collectors/collectors.py:598\u001b[0m, in \u001b[0;36mSyncDataCollector.__init__\u001b[0;34m(self, create_env_fn, policy, frames_per_batch, total_frames, device, storing_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, exploration_mode, return_same_td, reset_when_done, interruptor)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexploration_type \u001b[39m=\u001b[39m (\n\u001b[1;32m    594\u001b[0m     exploration_type \u001b[39mif\u001b[39;00m exploration_type \u001b[39melse\u001b[39;00m DEFAULT_EXPLORATION_TYPE\n\u001b[1;32m    595\u001b[0m )\n\u001b[1;32m    596\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_same_td \u001b[39m=\u001b[39m return_same_td\n\u001b[0;32m--> 598\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mreset()\n\u001b[1;32m    599\u001b[0m traj_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_env, device\u001b[39m=\u001b[39menv\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mview(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mbatch_size)\n\u001b[1;32m    600\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensordict\u001b[39m.\u001b[39mset(\n\u001b[1;32m    601\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mcollector\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtraj_ids\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    602\u001b[0m     traj_ids,\n\u001b[1;32m    603\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchrl/envs/common.py:498\u001b[0m, in \u001b[0;36mEnvBase.reset\u001b[0;34m(self, tensordict, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m     _reset \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m tensordict_reset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reset(tensordict, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    499\u001b[0m \u001b[39mif\u001b[39;00m tensordict_reset\u001b[39m.\u001b[39mdevice \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice:\n\u001b[1;32m    500\u001b[0m     tensordict_reset \u001b[39m=\u001b[39m tensordict_reset\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/delivery-RL/reinforcement/simulator_environment.py:150\u001b[0m, in \u001b[0;36mSimulatorEnv._reset\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m tensordict \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m tensordict\u001b[39m.\u001b[39mis_empty():\n\u001b[1;32m    149\u001b[0m     triple \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimulator\u001b[39m.\u001b[39mGetState()\n\u001b[0;32m--> 150\u001b[0m     tensors, ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(triple, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m    151\u001b[0m     masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_masks(tensors)\n\u001b[1;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_tensors(tensors, masks, ids)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/delivery-RL/networks/encoders/gamble_encoder.py:57\u001b[0m, in \u001b[0;36mGambleTripleEncoder.forward\u001b[0;34m(self, gamble_triple, current_time)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, gamble_triple: GambleTriple, current_time: \u001b[39mint\u001b[39m):\n\u001b[1;32m     54\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    Attention: the function adds BOS-fake items to every GambleTriple to strugle zero-input problem\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     o_tensor, o_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_tensor_with_ids(gamble_triple\u001b[39m.\u001b[39;49morders, item_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mo\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     58\u001b[0m                                                 current_time\u001b[39m=\u001b[39;49mcurrent_time)\n\u001b[1;32m     59\u001b[0m     c_tensor, c_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_tensor_with_ids(gamble_triple\u001b[39m.\u001b[39mcouriers, item_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     60\u001b[0m                                                 current_time\u001b[39m=\u001b[39mcurrent_time)\n\u001b[1;32m     61\u001b[0m     ar_tensor, ar_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_tensor_with_ids(gamble_triple\u001b[39m.\u001b[39mactive_routes, item_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mar\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     62\u001b[0m                                                   current_time\u001b[39m=\u001b[39mcurrent_time)\n",
      "File \u001b[0;32m~/delivery-RL/networks/encoders/gamble_encoder.py:85\u001b[0m, in \u001b[0;36mGambleTripleEncoder.make_tensor_with_ids\u001b[0;34m(self, sequence, item_type, current_time)\u001b[0m\n\u001b[1;32m     83\u001b[0m bos_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m item_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     tensors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([bos_tensor] \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39morder_enc(item, current_time) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sequence])\n\u001b[1;32m     86\u001b[0m \u001b[39melif\u001b[39;00m item_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     87\u001b[0m     tensors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([bos_tensor] \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcourier_enc(item, current_time) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sequence])\n",
      "File \u001b[0;32m~/delivery-RL/networks/encoders/gamble_encoder.py:85\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m bos_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_model, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m item_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     tensors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([bos_tensor] \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morder_enc(item, current_time) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sequence])\n\u001b[1;32m     86\u001b[0m \u001b[39melif\u001b[39;00m item_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     87\u001b[0m     tensors \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([bos_tensor] \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcourier_enc(item, current_time) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m sequence])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/delivery-RL/networks/encoders/positional_encoder.py:83\u001b[0m, in \u001b[0;36mPositionalEncoder.forward\u001b[0;34m(self, item, current_time)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, item, current_time):\n\u001b[1;32m     82\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_extractor(item, current_time, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_type)\n\u001b[0;32m---> 83\u001b[0m     encoded_points \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoint_encoder(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m features[\u001b[39m'\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     84\u001b[0m     encoded_numbers \u001b[39m=\u001b[39m [\n\u001b[1;32m     85\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumber_encoder(torch\u001b[39m.\u001b[39mtensor([n], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n\u001b[1;32m     86\u001b[0m             \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m features[\u001b[39m'\u001b[39m\u001b[39mnumbers\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     87\u001b[0m     ]\n\u001b[1;32m     89\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(torch\u001b[39m.\u001b[39mcat(encoded_points \u001b[39m+\u001b[39m encoded_numbers)\u001b[39m.\u001b[39mdetach())\n",
      "File \u001b[0;32m~/delivery-RL/networks/encoders/positional_encoder.py:83\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, item, current_time):\n\u001b[1;32m     82\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_extractor(item, current_time, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_type)\n\u001b[0;32m---> 83\u001b[0m     encoded_points \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoint_encoder(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m features[\u001b[39m'\u001b[39m\u001b[39mpoints\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     84\u001b[0m     encoded_numbers \u001b[39m=\u001b[39m [\n\u001b[1;32m     85\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumber_encoder(torch\u001b[39m.\u001b[39mtensor([n], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n\u001b[1;32m     86\u001b[0m             \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m features[\u001b[39m'\u001b[39m\u001b[39mnumbers\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     87\u001b[0m     ]\n\u001b[1;32m     89\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(torch\u001b[39m.\u001b[39mcat(encoded_points \u001b[39m+\u001b[39m encoded_numbers)\u001b[39m.\u001b[39mdetach())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/delivery-RL/networks/encoders/point_encoder.py:25\u001b[0m, in \u001b[0;36mPointEncoder.forward\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m     22\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([p\u001b[39m.\u001b[39mx], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     23\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([p\u001b[39m.\u001b[39my], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat([\n\u001b[0;32m---> 25\u001b[0m     torch\u001b[39m.\u001b[39msin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msin_layer_x(x)),\n\u001b[1;32m     26\u001b[0m     torch\u001b[39m.\u001b[39mcos(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcos_layer_x(x)),\n\u001b[1;32m     27\u001b[0m     torch\u001b[39m.\u001b[39msin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msin_layer_y(y)),\n\u001b[1;32m     28\u001b[0m     torch\u001b[39m.\u001b[39mcos(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcos_layer_y(y)),\n\u001b[1;32m     29\u001b[0m ], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mflatten()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"
     ]
    }
   ],
   "source": [
    "module = TensorDictModule(\n",
    "    net, in_keys=[('observation', 'tensors'), ('observation', 'masks')], out_keys=['logits', 'state_value']\n",
    ")\n",
    "\n",
    "policy_module_actor = ProbabilisticActor(\n",
    "    module=module,\n",
    "    in_keys=[\"logits\"],\n",
    "    distribution_class=Categorical,\n",
    "    return_log_prob=True,\n",
    ")\n",
    "\n",
    "collector = SyncDataCollector(\n",
    "    my_env,\n",
    "    policy_module_actor,\n",
    "    frames_per_batch=rl_settings['frames_per_epoch'],\n",
    "    total_frames=rl_settings['total_frames'],\n",
    "    split_trajs=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(rl_settings['frames_per_epoch']),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=rl_settings['batch_size']\n",
    ")\n",
    "\n",
    "advantage_module = CustomGAE(\n",
    "    gamma=rl_settings['gamma'], lmbda=rl_settings['lmbda'], value_network=module, average_gae=True, value_key='state_value'\n",
    ")\n",
    "\n",
    "loss_module = ClipPPOLoss(\n",
    "    actor=policy_module_actor,\n",
    "    critic=policy_module_actor,\n",
    "    advantage_key=\"advantage\",\n",
    "    clip_epsilon=rl_settings['clip_epsilon'],\n",
    "    entropy_bonus=bool(rl_settings['entropy_eps']),\n",
    "    entropy_coef=rl_settings['entropy_eps'],\n",
    "    # these keys match by default but we set this for completeness\n",
    "    value_target_key=advantage_module.value_target_key,\n",
    "    critic_coef=1.0,\n",
    "    gamma=0.99,\n",
    "    loss_critic_type=\"smooth_l1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"delivery-RL\", \n",
    "    name=f\"increase_max_items\", \n",
    "    config={\n",
    "        'hyperparams': hyperparams,\n",
    "        'training_settings': training_settings,\n",
    "        'device': device,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64000 [03:19<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer time: 1.6035079956054688inner time: 15.709347009658813\n",
      "outer time: 1.3045949935913086inner time: 20.968085050582886\n",
      "outer time: 1.4153859615325928inner time: 21.76977801322937\n",
      "outer time: 1.396456003189087"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb Cell 16\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss_value \u001b[39m=\u001b[39m (\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     loss_vals[\u001b[39m\"\u001b[39m\u001b[39mloss_objective\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m+\u001b[39m loss_vals[\u001b[39m\"\u001b[39m\u001b[39mloss_critic\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m+\u001b[39m loss_vals[\u001b[39m\"\u001b[39m\u001b[39mloss_entropy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Optimization: backward, grad clipping and optim step\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m loss_value\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# this is not strictly mandatory but it's good practice to keep\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# your gradient norm bounded\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#Y204sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(loss_module\u001b[39m.\u001b[39mparameters(), rl_settings[\u001b[39m'\u001b[39m\u001b[39mmax_grad_norm\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam(list(loss_module.parameters()) + list(encoder.parameters()), lr=rl_settings['lr'])\n",
    "pbar = tqdm(total=rl_settings['total_frames'])\n",
    "\n",
    "start_outer = time.time()\n",
    "for i, tensordict_data in enumerate(collector):\n",
    "    start_inner = time.time()\n",
    "    print(f'outer time: {start_inner - start_outer}', end='')\n",
    "    for _ in range(rl_settings['num_epochs']):\n",
    "        # We'll need an \"advantage\" signal to make PPO work.\n",
    "        # We re-compute it at each epoch as its value depends on the value\n",
    "        # network which is updated in the inner loop.\n",
    "        advantage_module(tensordict_data)\n",
    "        data_view = tensordict_data.reshape(-1)\n",
    "        replay_buffer.extend(data_view.cpu())\n",
    "        for _ in range(rl_settings['frames_per_epoch'] // rl_settings['batch_size']):\n",
    "            subdata = replay_buffer.sample()\n",
    "            loss_vals = loss_module(subdata.to(device))\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            # Optimization: backward, grad clipping and optim step\n",
    "            loss_value.backward()\n",
    "            # this is not strictly mandatory but it's good practice to keep\n",
    "            # your gradient norm bounded\n",
    "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), rl_settings['max_grad_norm'])\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "            wandb.log({\n",
    "                \"loss_total\": loss_value.item(),\n",
    "                'loss_objective': loss_vals['loss_objective'],\n",
    "                'loss_critic': loss_vals['loss_critic'],\n",
    "                'loss_entropy': loss_vals['loss_entropy']\n",
    "                })\n",
    "            \n",
    "    dsp = NeuralDispatch(net, encoder)\n",
    "    cr = get_CR(get_batch_quality_metrics(dsp, Simulator, batch_size=training_settings['eval_batch_size'], num_steps=training_settings['eval_num_steps']))\n",
    "    wandb.log({'cr': cr})\n",
    "    \n",
    "    start_outer = time.time()\n",
    "    print(f'inner time: {start_outer - start_inner}', end='\\n')    \n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensordict.nn import TensorDictModule\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchrl.collectors import SyncDataCollector, MultiaSyncDataCollector, MultiSyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.envs import (\n",
    "    Compose,\n",
    "    DoubleToFloat,\n",
    "    ObservationNorm,\n",
    "    StepCounter,\n",
    "    TransformedEnv,\n",
    ")\n",
    "from torchrl.envs.libs.gym import GymEnv\n",
    "from torchrl.envs.utils import check_env_specs, set_exploration_mode\n",
    "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
    "from torchrl.objectives import ClipPPOLoss\n",
    "from torchrl.objectives.value import GAE\n",
    "from torchrl.envs import EnvBase\n",
    "from tensordict.tensordict import TensorDictBase, TensorDict\n",
    "from typing import Optional\n",
    "import gym\n",
    "from torchrl.data import CompositeSpec, BoundedTensorSpec, UnboundedContinuousTensorSpec, BinaryDiscreteTensorSpec, OneHotDiscreteTensorSpec, DiscreteTensorSpec, UnboundedDiscreteTensorSpec\n",
    "\n",
    "\n",
    "class SimulatorEnv(EnvBase):\n",
    "    def __init__(self, simulator: type[Simulator], seed=None, device=\"cpu\"):\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "\n",
    "        self.load_settings()\n",
    "        \n",
    "        # self.simulators = [simulator(seed=i) for i in range(sub_batch_size)]\n",
    "        self.simulator = simulator()\n",
    "        self.encoder = GambleTripleEncoder(number_enc_dim=self.number_enc_dim, d_model=self.d_model, point_enc_dim=self.point_enc_dim)\n",
    "        # self.model = ScoringInterface(net)\n",
    "        # triples = [simulator.GetState() for simulator in self.simulators]\n",
    "        # self.model.encode_input(triples, 0)\n",
    "        self._make_specs()\n",
    "        \n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.long).random_().item()\n",
    "        self.set_seed(seed)\n",
    "\n",
    "    def load_settings(self):\n",
    "        with open('configs/rl_settings.json') as f:\n",
    "            settings = json.load(f)\n",
    "        self.max_num_orders = settings['max_num_orders']\n",
    "        self.max_num_couriers = settings['max_num_couriers']\n",
    "        self.max_num_active_routes = settings['max_num_active_routes']\n",
    "\n",
    "        with open('configs/network_hyperparams.json') as f:\n",
    "            hyperparams = json.load(f)\n",
    "        self.number_enc_dim = hyperparams['number_enc_dim']\n",
    "        self.d_model = hyperparams['d_model']\n",
    "        self.point_enc_dim = hyperparams['point_enc_dim']\n",
    "\n",
    "\n",
    "    def make_masks(self, tensors):\n",
    "        masks = {\n",
    "            'o': torch.tensor([True] + [False] * (len(tensors['o']) - 1), device=device, dtype=torch.bool),\n",
    "            'c': torch.tensor([True] + [False] * (len(tensors['c']) - 1), device=device, dtype=torch.bool),\n",
    "            'ar': torch.tensor([True] + [False] * (len(tensors['ar']) - 1), device=device, dtype=torch.bool)\n",
    "        }\n",
    "\n",
    "        return masks\n",
    "    \n",
    "    def pad_tensors(self, tensors, masks, ids):\n",
    "        '''\n",
    "        Pads tensors to max_limits inplace\n",
    "        '''\n",
    "        max_limits = {\n",
    "            'o': self.max_num_orders,\n",
    "            'c': self.max_num_couriers,\n",
    "            'ar': self.max_num_active_routes\n",
    "        }\n",
    "        for item_type in ['o', 'c', 'ar']:\n",
    "            length = tensors[item_type].shape[0]\n",
    "            tensors[item_type] = F.pad(input=tensors[item_type], pad=(0, 0, 0, max_limits[item_type] - length), mode='constant', value=0.0)\n",
    "            masks[item_type] = F.pad(input=masks[item_type], pad=(0, max_limits[item_type] - length), mode='constant', value=True)\n",
    "            ids[item_type] = F.pad(input=ids[item_type], pad=(0, max_limits[item_type] - length), mode='constant', value=-1)\n",
    "\n",
    "        \n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        '''\n",
    "        tensordict['action'] - a np.array of indexes (not IDs) of couriers assigned for the given order. If there is no courier assigned self.max_num_couriers is provided.\n",
    "        BOS-fake items are included.\n",
    "        '''\n",
    "\n",
    "        assignments = []\n",
    "        assigned_o_idxs = set()\n",
    "        assigned_c_idxs = set()\n",
    "        for o_idx, c_idx in enumerate(tensordict['action'].numpy()):\n",
    "            if c_idx != self.max_num_couriers  \\\n",
    "                and not tensordict['observation', 'masks', 'o'][o_idx] \\\n",
    "                and not tensordict['observation', 'masks', 'c'][c_idx] \\\n",
    "                and (o_idx not in assigned_o_idxs) and (c_idx not in assigned_c_idxs) \\\n",
    "            :\n",
    "                assignment = (tensordict['observation', 'ids', 'o'][o_idx].item(), tensordict['observation', 'ids', 'c'][c_idx].item())\n",
    "                assignments.append(assignment)\n",
    "                assigned_o_idxs.add(o_idx)\n",
    "                assigned_c_idxs.add(c_idx)\n",
    "\n",
    "        # print(assignments)\n",
    "        # print(self.simulator.GetState())\n",
    "        self.simulator.Next(assignments)\n",
    "        triple = self.simulator.GetState()\n",
    "        tensors, ids = self.encoder(triple, 0)\n",
    "        masks = self.make_masks(tensors)\n",
    "        self.pad_tensors(tensors, masks, ids)\n",
    "\n",
    "        out = TensorDict(\n",
    "            {\n",
    "                \"next\": {\n",
    "                    \"observation\": {\n",
    "                        'tensors': {\n",
    "                            'o': tensors['o'],\n",
    "                            'c': tensors['c'],\n",
    "                            'ar': tensors['ar']     \n",
    "                        },\n",
    "                        'masks': {\n",
    "                            'o': masks['o'],\n",
    "                            'c': masks['c'],\n",
    "                            'ar': masks['ar']     \n",
    "                        },\n",
    "                        'ids': {\n",
    "                            'o': ids['o'],\n",
    "                            'c': ids['c'],\n",
    "                            'ar': ids['ar']\n",
    "                        }\n",
    "                    },\n",
    "                    \"reward\": torch.tensor(0, dtype=torch.float32),\n",
    "                    \"done\": torch.tensor(False, dtype=torch.bool),\n",
    "                    # \"reward\": torch.tensor([0] * sub_batch_size, dtype=torch.float32),\n",
    "                    # \"done\": torch.tensor([False] * sub_batch_size, dtype=torch.bool),\n",
    "                }\n",
    "            },\n",
    "            tensordict.shape\n",
    "            # batch_size=tensordict.shape[0]\n",
    "        )\n",
    "        # print(out['next', 'observation', 'ids', 'o'])\n",
    "        return out\n",
    "    \n",
    "    def _reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        if tensordict is None or tensordict.is_empty():\n",
    "            triple = self.simulator.GetState()\n",
    "            tensors, ids = self.encoder(triple, 0)\n",
    "            masks = self.make_masks(tensors)\n",
    "            self.pad_tensors(tensors, masks, ids)\n",
    "            \n",
    "            return TensorDict(\n",
    "            {\n",
    "                \"observation\": {\n",
    "                    'tensors': {\n",
    "                        'o': tensors['o'],\n",
    "                        'c': tensors['c'],\n",
    "                        'ar': tensors['ar']     \n",
    "                    },\n",
    "                    'masks': {\n",
    "                        'o': masks['o'],\n",
    "                        'c': masks['c'],\n",
    "                        'ar': masks['ar']     \n",
    "                    },\n",
    "                    'ids': {\n",
    "                        'o': ids['o'],\n",
    "                        'c': ids['c'],\n",
    "                        'ar': ids['ar']\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            # batch_size=[sub_batch_size]\n",
    "            batch_size=self.batch_size\n",
    "        ) \n",
    "        return tensordict\n",
    "    \n",
    "    def _set_seed(self, seed: Optional[int]):\n",
    "        rng = torch.manual_seed(seed)\n",
    "        self.rng = rng\n",
    "\n",
    "    def _make_specs(self) -> None:\n",
    "        self.action_spec = DiscreteTensorSpec(\n",
    "            n=self.max_num_couriers + 1,\n",
    "            dtype=torch.int,\n",
    "            shape=[self.max_num_orders]\n",
    "        )\n",
    "        observation_spec = CompositeSpec(\n",
    "            tensors = CompositeSpec(\n",
    "                o = UnboundedContinuousTensorSpec(\n",
    "                    shape=[self.max_num_orders, self.encoder.d_model],\n",
    "                    dtype=torch.float\n",
    "                ),\n",
    "                c = UnboundedContinuousTensorSpec(\n",
    "                    shape=[self.max_num_couriers, self.encoder.d_model],\n",
    "                    dtype=torch.float\n",
    "                ),\n",
    "                ar = UnboundedContinuousTensorSpec(\n",
    "                    shape=[self.max_num_active_routes, self.encoder.d_model],\n",
    "                    dtype=torch.float\n",
    "                ),\n",
    "                # shape=[sub_batch_size]\n",
    "            ),\n",
    "            masks = CompositeSpec(\n",
    "                o = DiscreteTensorSpec(\n",
    "                    n=2,\n",
    "                    dtype=torch.bool,\n",
    "                    shape=[self.max_num_orders]\n",
    "                ),\n",
    "                c = DiscreteTensorSpec(\n",
    "                    n=2,\n",
    "                    dtype=torch.bool,\n",
    "                    shape=[self.max_num_couriers]\n",
    "                ),\n",
    "                ar = DiscreteTensorSpec(\n",
    "                    n=2,\n",
    "                    dtype=torch.bool,\n",
    "                    shape=[self.max_num_active_routes]\n",
    "                ),\n",
    "                # shape=[sub_batch_size]\n",
    "            ),\n",
    "            ids = CompositeSpec(\n",
    "                o = UnboundedDiscreteTensorSpec(\n",
    "                    dtype=torch.int,\n",
    "                    shape=[self.max_num_orders]\n",
    "                ),\n",
    "                c = UnboundedDiscreteTensorSpec(\n",
    "                    dtype=torch.int,\n",
    "                    shape=[self.max_num_couriers]\n",
    "                ),\n",
    "                ar = UnboundedDiscreteTensorSpec(\n",
    "                    dtype=torch.int,\n",
    "                    shape=[self.max_num_active_routes]\n",
    "                ),\n",
    "                # shape=[sub_batch_size]\n",
    "            ), \n",
    "            # shape=[sub_batch_size]\n",
    "        )\n",
    "        # if not isinstance(observation_spec, CompositeSpec):\n",
    "        observation_spec = CompositeSpec(observation=observation_spec) # shape=[sub_batch_size]\n",
    "            \n",
    "        self.observation_spec = observation_spec\n",
    "        self.reward_spec = UnboundedContinuousTensorSpec(\n",
    "            # shape=[sub_batch_size],\n",
    "            shape=[1],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.done_spec = BinaryDiscreteTensorSpec(\n",
    "            # n=sub_batch_size,\n",
    "            # shape=[sub_batch_size],\n",
    "            n=1,\n",
    "            shape=[1],\n",
    "            dtype=torch.bool\n",
    "        )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_env = SimulatorEnv(Simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = TransformedEnv(\n",
    "#     my_env,\n",
    "    # Compose(\n",
    "    #     # normalize observations\n",
    "    #     # ObservationNorm(in_keys=[\"observation\"]),\n",
    "    #     # DoubleToFloat(in_keys=[\"observation\"]),\n",
    "    #     StepCounter(),\n",
    "    # ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    observation: CompositeSpec(\n",
      "        tensors: CompositeSpec(\n",
      "            o: UnboundedContinuousTensorSpec(\n",
      "                 shape=torch.Size([100, 512]), space=None, device=cpu, dtype=torch.float32, domain=continuous),\n",
      "            c: UnboundedContinuousTensorSpec(\n",
      "                 shape=torch.Size([100, 512]), space=None, device=cpu, dtype=torch.float32, domain=continuous),\n",
      "            ar: UnboundedContinuousTensorSpec(\n",
      "                 shape=torch.Size([100, 512]), space=None, device=cpu, dtype=torch.float32, domain=continuous), device=cpu, shape=torch.Size([])),\n",
      "        masks: CompositeSpec(\n",
      "            o: DiscreteTensorSpec(\n",
      "                 shape=torch.Size([100]), space=DiscreteBox(n=2), device=cpu, dtype=torch.bool, domain=discrete),\n",
      "            c: DiscreteTensorSpec(\n",
      "                 shape=torch.Size([100]), space=DiscreteBox(n=2), device=cpu, dtype=torch.bool, domain=discrete),\n",
      "            ar: DiscreteTensorSpec(\n",
      "                 shape=torch.Size([100]), space=DiscreteBox(n=2), device=cpu, dtype=torch.bool, domain=discrete), device=cpu, shape=torch.Size([])),\n",
      "        ids: CompositeSpec(\n",
      "            o: UnboundedDiscreteTensorSpec(\n",
      "                 shape=torch.Size([100]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous),\n",
      "            c: UnboundedDiscreteTensorSpec(\n",
      "                 shape=torch.Size([100]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous),\n",
      "            ar: UnboundedDiscreteTensorSpec(\n",
      "                 shape=torch.Size([100]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "     shape=torch.Size([1]), space=None, device=cpu, dtype=torch.float32, domain=continuous)\n",
      "input_spec: CompositeSpec(\n",
      "    action: DiscreteTensorSpec(\n",
      "         shape=torch.Size([100]), space=DiscreteBox(n=101), device=cpu, dtype=torch.int32, domain=discrete), device=cpu, shape=torch.Size([]))\n",
      "action_spec (as defined by input_spec): DiscreteTensorSpec(\n",
      "     shape=torch.Size([100]), space=DiscreteBox(n=101), device=cpu, dtype=torch.int32, domain=discrete)\n"
     ]
    }
   ],
   "source": [
    "# env.transform[0].init_stats(num_iter=1000, reduce_dim=0, cat_dim=0)\n",
    "# print(\"normalization constant shape:\", env.transform[0].loc.shape)\n",
    "print(\"observation_spec:\", my_env.observation_spec)\n",
    "print(\"reward_spec:\", my_env.reward_spec)\n",
    "print(\"input_spec:\", my_env.input_spec)\n",
    "print(\"action_spec (as defined by input_spec):\", my_env.action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(my_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout = my_env.rollout(10)\n",
    "print(\"rollout of three steps:\", rollout)\n",
    "print(\"Shape of the rollout TensorDict:\", rollout.batch_size)\n",
    "rollout.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = TensorDictModule(\n",
    "    net, in_keys=[('observation', 'tensors'), ('observation', 'masks')], out_keys=['logits', 'state_value']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td = my_env.reset()\n",
    "# net(td['observation', 'tensors'].to_dict(), td['observation', 'masks'].to_dict())\n",
    "# td['observation', 'tensors'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running policy: TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        logits: Tensor(shape=torch.Size([100, 101]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.ids.ar: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        observation.ids.c: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        observation.ids.o: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        observation.masks.ar: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation.masks.c: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation.masks.o: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation.tensors.ar: Tensor(shape=torch.Size([100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.tensors.c: Tensor(shape=torch.Size([100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.tensors.o: Tensor(shape=torch.Size([100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        state_value: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "print(\"Running policy:\", module(my_env.reset()).flatten_keys('.'))\n",
    "# env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Sequence, Union\n",
    "from tensordict.tensordict import TensorDictBase\n",
    "from torchrl.data.tensor_specs import TensorSpec\n",
    "from torchrl.modules.tensordict_module.common import SafeModule\n",
    "\n",
    "\n",
    "class ProbabilisticActorPolivyAvg(ProbabilisticActor):\n",
    "    def __init__(self, module: SafeModule, in_keys: str | Sequence[str], out_keys: Sequence[str] | None = None, spec: TensorSpec | None = None, **kwargs):\n",
    "        super().__init__(module, in_keys, out_keys, spec, **kwargs)\n",
    "    \n",
    "    def forward(self, tensordict: TensorDictBase, tensordict_out: TensorDictBase | None = None, **kwargs) -> TensorDictBase:\n",
    "        tens = super().forward(tensordict, tensordict_out, **kwargs)\n",
    "        input = tens['sample_log_prob']\n",
    "        mask = tens['observation', 'masks', 'o']\n",
    "\n",
    "        assert (len(input.shape) == 2 and len(mask.shape) == 2) or (len(input.shape) == 1 and len(mask.shape) == 1), 'dims should be [bs, ord] or [ord]'\n",
    "\n",
    "        sums = torch.sum(torch.where(mask, input, 0), dim=-1)\n",
    "        nums = torch.sum(torch.where(mask, 1, 0), dim=-1)\n",
    "\n",
    "        tens['sample_log_prob'] = torch.where(nums > 0, sums / nums, 0)\n",
    "\n",
    "        return tens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensordict.nn.distributions import Categorical\n",
    "from torch.distributions.categorical import Categorical\n",
    "policy_module_actor = ProbabilisticActor(\n",
    "    module=module,\n",
    "    in_keys=[\"logits\"],\n",
    "    distribution_class=Categorical,\n",
    "    # distribution_kwargs={\n",
    "    #     \"n\": env.action_spec.space.n,\n",
    "    # },\n",
    "    return_log_prob=True,\n",
    "    # we'll need the log-prob for the numerator of the importance weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LogPolicyAvg(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, input, mask):\n",
    "#         assert (len(input.shape) == 2 and len(mask.shape) == 2) or (len(input.shape) == 1 and len(mask.shape) == 1), 'dims should be [bs, ord] or [ord]'\n",
    "\n",
    "#         sums = torch.sum(torch.where(mask, input, 0), dim=-1)\n",
    "#         nums = torch.sum(torch.where(mask, 1, 0), dim=-1)\n",
    "\n",
    "#         return torch.where(nums > 0, sums / nums, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensordict.nn import TensorDictModule, TensorDictSequential\n",
    "# final_module = TensorDictSequential(\n",
    "#     policy_module_actor,\n",
    "#     TensorDictModule(LogPolicyAvg(), in_keys=['sample_log_prob', ('observation', 'masks', 'o')], out_keys=['sample_log_prob']),\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_module = ValueOperator(\n",
    "#     module=net,\n",
    "#     in_keys=[('observation', 'tensors'), ('observation', 'masks')], \n",
    "#     out_keys=['logits', 'values']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = SyncDataCollector(\n",
    "    my_env,\n",
    "    policy_module_actor,\n",
    "    frames_per_batch=1,\n",
    "    total_frames=5,\n",
    "    split_trajs=False,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        collector.traj_ids: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        logits: Tensor(shape=torch.Size([1, 100, 101]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.ids.ar: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.ids.c: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.ids.o: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.masks.ar: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.masks.c: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.masks.o: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.tensors.ar: Tensor(shape=torch.Size([1, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.observation.tensors.c: Tensor(shape=torch.Size([1, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.observation.tensors.o: Tensor(shape=torch.Size([1, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.reward: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.ids.ar: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.ids.c: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.ids.o: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.masks.ar: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.masks.c: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.masks.o: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.tensors.ar: Tensor(shape=torch.Size([1, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.tensors.c: Tensor(shape=torch.Size([1, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.tensors.o: Tensor(shape=torch.Size([1, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        sample_log_prob: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        state_value: Tensor(shape=torch.Size([1, 100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([1]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, c in enumerate(collector):\n",
    "    if i == 3:\n",
    "        break\n",
    "c.flatten_keys('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.objectives.ppo import PPOLoss\n",
    "from torchrl.objectives.utils import hold_out_net\n",
    "from torchrl.envs.utils import step_mdp\n",
    "from typing import Union, Tuple, List\n",
    "from torchrl.modules import SafeModule\n",
    "from torchrl.objectives.value.utils import _custom_conv1d, _make_gammas_tensor\n",
    "\n",
    "class CustomGAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gamma: Union[float, torch.Tensor],\n",
    "        lmbda: float,\n",
    "        value_network: SafeModule,\n",
    "        average_gae: bool = False,\n",
    "        differentiable: bool = False,\n",
    "        advantage_key: Union[str, Tuple] = \"advantage\",\n",
    "        value_target_key: Union[str, Tuple] = \"value_target\",\n",
    "        value_key: Union[str, Tuple] = \"state_value\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        try:\n",
    "            device = next(value_network.parameters()).device\n",
    "        except StopIteration:\n",
    "            device = torch.device(\"cpu\")\n",
    "        self.register_buffer(\"gamma\", torch.tensor(gamma, device=device))\n",
    "        self.register_buffer(\"lmbda\", torch.tensor(lmbda, device=device))\n",
    "        self.value_network = value_network\n",
    "        self.value_key = value_key\n",
    "        if value_key not in value_network.out_keys:\n",
    "            raise KeyError(\n",
    "                f\"value key '{value_key}' not found in value network out_keys.\"\n",
    "            )\n",
    "\n",
    "        self.average_gae = average_gae\n",
    "        self.differentiable = differentiable\n",
    "\n",
    "        self.advantage_key = advantage_key\n",
    "        self.value_target_key = value_target_key\n",
    "\n",
    "        self.in_keys = (\n",
    "            value_network.in_keys\n",
    "            + [(\"next\", \"reward\"), (\"next\", \"done\")]\n",
    "            + [(\"next\", in_key) for in_key in value_network.in_keys]\n",
    "        )\n",
    "        self.out_keys = [self.advantage_key, self.value_target_key]\n",
    "\n",
    "    @property\n",
    "    def is_functional(self):\n",
    "        return (\n",
    "            \"_is_stateless\" in self.value_network.__dict__\n",
    "            and self.value_network.__dict__[\"_is_stateless\"]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        tensordict: TensorDictBase,\n",
    "        *unused_args,\n",
    "        params: Optional[List[torch.Tensor]] = None,\n",
    "        target_params: Optional[List[torch.Tensor]] = None,\n",
    "    ) -> TensorDictBase:\n",
    "        if tensordict.batch_dims < 1:\n",
    "            raise RuntimeError(\n",
    "                \"Expected input tensordict to have at least one dimensions, got\"\n",
    "                f\"tensordict.batch_size = {tensordict.batch_size}\"\n",
    "            )\n",
    "        reward = tensordict.get((\"next\", \"reward\"))\n",
    "        gamma, lmbda = self.gamma, self.lmbda\n",
    "        kwargs = {}\n",
    "        if self.is_functional and params is None:\n",
    "            raise RuntimeError(\n",
    "                \"Expected params to be passed to advantage module but got none.\"\n",
    "            )\n",
    "        if params is not None:\n",
    "            kwargs[\"params\"] = params\n",
    "        with hold_out_net(self.value_network):\n",
    "            # we may still need to pass gradient, but we don't want to assign grads to\n",
    "            # value net params\n",
    "            self.value_network(tensordict, **kwargs)\n",
    "\n",
    "        value = tensordict.get(self.value_key)\n",
    "\n",
    "        step_td = step_mdp(tensordict)\n",
    "        if target_params is not None:\n",
    "            # we assume that target parameters are not differentiable\n",
    "            kwargs[\"params\"] = target_params\n",
    "        elif \"params\" in kwargs:\n",
    "            kwargs[\"params\"] = kwargs[\"params\"].detach()\n",
    "        with hold_out_net(self.value_network):\n",
    "            # we may still need to pass gradient, but we don't want to assign grads to\n",
    "            # value net params\n",
    "            self.value_network(step_td, **kwargs)\n",
    "        next_value = step_td.get(self.value_key)\n",
    "        done = tensordict.get((\"next\", \"done\"))\n",
    "               \n",
    "        adv, value_target = self.vec_generalized_advantage_estimate(\n",
    "            gamma, lmbda, value, next_value, reward, done\n",
    "        )\n",
    "\n",
    "        if self.average_gae:\n",
    "            loc = adv.mean()\n",
    "            scale = adv.std().clamp_min(1e-4)\n",
    "            adv = adv - loc\n",
    "            adv = adv / scale\n",
    "\n",
    "        tensordict.set(self.advantage_key, adv)\n",
    "        tensordict.set(self.value_target_key, value_target)\n",
    "\n",
    "        return tensordict\n",
    "    \n",
    "    def vec_generalized_advantage_estimate(self, \n",
    "        gamma: float,\n",
    "        lmbda: float,\n",
    "        state_value: torch.Tensor, # [*bs, ts, 100]\n",
    "        next_state_value: torch.Tensor, # [*bs, ts, 100]\n",
    "        reward: torch.Tensor, # [*bs, ts, 1]\n",
    "        done: torch.Tensor, # [*bs, ts, 1]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Get generalized advantage estimate of a trajectory.\n",
    "\n",
    "        Refer to \"HIGH-DIMENSIONAL CONTINUOUS CONTROL USING GENERALIZED ADVANTAGE ESTIMATION\"\n",
    "        https://arxiv.org/pdf/1506.02438.pdf for more context.\n",
    "\n",
    "        Args:\n",
    "            gamma (scalar): exponential mean discount.\n",
    "            lmbda (scalar): trajectory discount.\n",
    "            state_value (Tensor): value function result with old_state input.\n",
    "                must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor\n",
    "            next_state_value (Tensor): value function result with new_state input.\n",
    "                must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor\n",
    "            reward (Tensor): reward of taking actions in the environment.\n",
    "                must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor\n",
    "            done (Tensor): boolean flag for end of episode.\n",
    "\n",
    "        \"\"\"\n",
    "        # for tensor in (next_state_value, state_value, reward, done):\n",
    "        #     if tensor.shape[-1] != 1:\n",
    "        #         raise RuntimeError(\n",
    "        #             \"Last dimension of generalized_advantage_estimate inputs must be a singleton dimension.\"\n",
    "        #         )\n",
    "        state_value = state_value.unsqueeze(-3).transpose(-1, -3)\n",
    "        next_state_value = next_state_value.unsqueeze(-3).transpose(-1, -3)\n",
    "        reward = reward.unsqueeze(-3).transpose(-1, -3)\n",
    "        done = done.unsqueeze(-3).transpose(-1, -3)\n",
    "\n",
    "        dtype = state_value.dtype\n",
    "        not_done = 1 - done.to(dtype)\n",
    "        *batch_size, time_steps = not_done.shape[:-1]\n",
    "\n",
    "        value = gamma * lmbda\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            # create tensor while ensuring that gradients are passed\n",
    "            gammalmbdas = torch.ones_like(state_value) * not_done * value\n",
    "        else:\n",
    "            gammalmbdas = torch.full_like(state_value, value) * not_done\n",
    "        gammalmbdas = _make_gammas_tensor(gammalmbdas, time_steps, True) # in: [*bs, 100, ts, 1]\n",
    "        gammalmbdas = gammalmbdas.cumprod(-2)\n",
    "        # first_below_thr = gammalmbdas < 1e-7\n",
    "        # # if we have multiple gammas, we only want to truncate if _all_ of\n",
    "        # # the geometric sequences fall below the threshold\n",
    "        # first_below_thr = first_below_thr.all(axis=0)\n",
    "        # if first_below_thr.any():\n",
    "        #     gammalmbdas = gammalmbdas[..., :first_below_thr, :]\n",
    "\n",
    "        td0 = reward + not_done * gamma * next_state_value - state_value\n",
    "\n",
    "        if len(batch_size) > 1:\n",
    "            td0 = td0.flatten(0, len(batch_size) - 1)\n",
    "        elif not len(batch_size):\n",
    "            td0 = td0.unsqueeze(0)\n",
    "\n",
    "        advantage = _custom_conv1d(td0.transpose(-2, -1), gammalmbdas)\n",
    "\n",
    "        if len(batch_size) > 1:\n",
    "            advantage = advantage.unflatten(0, batch_size)\n",
    "        elif not len(batch_size):\n",
    "            advantage = advantage.squeeze(0)\n",
    "\n",
    "        advantage = advantage.transpose(-2, -1)\n",
    "        value_target = advantage + state_value\n",
    "\n",
    "        value_target = value_target.transpose(-1, -3).squeeze(-3)\n",
    "        advantage = advantage.transpose(-1, -3).squeeze(-3)\n",
    "\n",
    "        return advantage.unsqueeze(-1), value_target\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data import ReplayBuffer, LazyTensorStorage\n",
    "\n",
    "num_cells = 256  # number of cells in each layer\n",
    "lr = 3e-4\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "frame_skip = 1\n",
    "frames_per_batch = 16 // frame_skip\n",
    "# For a complete training, bring the number of frames up to 1M\n",
    "total_frames = 200_000 // frame_skip\n",
    "\n",
    "sub_batch_size = 16  # cardinality of the sub-samples gathered from the current data in the inner loop\n",
    "num_epochs = 2  # optimisation steps per batch of data collected\n",
    "clip_epsilon = (\n",
    "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
    ")\n",
    "gamma = 0.99\n",
    "lmbda = 0.95\n",
    "entropy_eps = 1e-4\n",
    "\n",
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(frames_per_batch),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    "    batch_size=sub_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "advantage_module = CustomGAE(\n",
    "    gamma=gamma, lmbda=lmbda, value_network=module, average_gae=True, value_key='state_value'\n",
    ")\n",
    "\n",
    "loss_module = ClipPPOLoss(\n",
    "    actor=policy_module_actor,\n",
    "    critic=policy_module_actor,\n",
    "    advantage_key=\"advantage\",\n",
    "    clip_epsilon=clip_epsilon,\n",
    "    entropy_bonus=bool(entropy_eps),\n",
    "    entropy_coef=entropy_eps,\n",
    "    # these keys match by default but we set this for completeness\n",
    "    value_target_key=advantage_module.value_target_key,\n",
    "    critic_coef=1.0,\n",
    "    gamma=0.99,\n",
    "    loss_critic_type=\"smooth_l1\",\n",
    ")\n",
    "\n",
    "optim = torch.optim.Adam(loss_module.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(collector):\n",
    "    if i == 5:\n",
    "        break\n",
    "    advantage_module(c)\n",
    "    data_view = c.reshape(-1)\n",
    "    replay_buffer.extend(data_view.cpu())\n",
    "\n",
    "subdata = replay_buffer.sample()\n",
    "# advantage_module(subdata).flatten_keys('.')\n",
    "# loss_vals = loss_module(subdata)\n",
    "# loss_value = (\n",
    "#     loss_vals[\"loss_objective\"]\n",
    "#     + loss_vals[\"loss_critic\"]\n",
    "#     + loss_vals[\"loss_entropy\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        advantage: Tensor(shape=torch.Size([5, 100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        collector.traj_ids: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        logits: Tensor(shape=torch.Size([5, 100, 101]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.ids.ar: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.ids.c: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.ids.o: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        next.observation.masks.ar: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.masks.c: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.masks.o: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next.observation.tensors.ar: Tensor(shape=torch.Size([5, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.observation.tensors.c: Tensor(shape=torch.Size([5, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.observation.tensors.o: Tensor(shape=torch.Size([5, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.reward: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.ids.ar: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.ids.c: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.ids.o: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        observation.masks.ar: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.masks.c: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.masks.o: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation.tensors.ar: Tensor(shape=torch.Size([5, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.tensors.c: Tensor(shape=torch.Size([5, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.tensors.o: Tensor(shape=torch.Size([5, 100, 512]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        sample_log_prob: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        state_value: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        value_target: Tensor(shape=torch.Size([5, 100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([5]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdata.flatten_keys('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vals = loss_module(subdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        ESS: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        entropy: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        loss_critic: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        loss_entropy: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        loss_objective: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200000 [00:18<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=total_frames * frame_skip)\n",
    "eval_str = \"\"\n",
    "\n",
    "# We iterate over the collector until it reaches the total number of frames it was\n",
    "# designed to collect:\n",
    "for i, tensordict_data in enumerate(collector):\n",
    "    # we now have a batch of data to work with. Let's learn something from it.\n",
    "    for _ in range(num_epochs):\n",
    "        # We'll need an \"advantage\" signal to make PPO work.\n",
    "        # We re-compute it at each epoch as its value depends on the value\n",
    "        # network which is updated in the inner loop.\n",
    "        advantage_module(tensordict_data)\n",
    "        data_view = tensordict_data.reshape(-1)\n",
    "        replay_buffer.extend(data_view.cpu())\n",
    "        for _ in range(frames_per_batch // sub_batch_size):\n",
    "            subdata = replay_buffer.sample(sub_batch_size)\n",
    "            loss_vals = loss_module(subdata.to(device))\n",
    "            loss_value = (\n",
    "                loss_vals[\"loss_objective\"]\n",
    "                + loss_vals[\"loss_critic\"]\n",
    "                + loss_vals[\"loss_entropy\"]\n",
    "            )\n",
    "\n",
    "            # Optimization: backward, grad clipping and optim step\n",
    "            loss_value.backward()\n",
    "            # this is not strictly mandatory but it's good practice to keep\n",
    "            # your gradient norm bounded\n",
    "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2\n",
    "\n",
    "class TestEnv(EnvBase):\n",
    "    def __init__(self, seed=None, device=\"cpu\"):\n",
    "        super().__init__(device=device, batch_size=[bs])\n",
    "        self._make_specs()\n",
    "        \n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.long).random_().item()\n",
    "        self.set_seed(seed)\n",
    "        \n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        '''\n",
    "        tensordict['action'] - a np.array of indexes of couriers assigned for the given order. If there is no courier assigned -1 is provided.\n",
    "        '''\n",
    "        print('next')\n",
    "        out = TensorDict(\n",
    "            {\n",
    "                \"next\": {\n",
    "                    \"observation\": TensorDict({\n",
    "                        'a': torch.tensor([[-1, -2], [-4, -5]], dtype=torch.float),\n",
    "                        'b': torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float),\n",
    "                        },\n",
    "                        batch_size=[bs]\n",
    "                    ),\n",
    "                    \"reward\": torch.tensor([0] * bs, dtype=torch.float32),\n",
    "                    \"done\": torch.tensor([False] * bs, dtype=torch.bool),\n",
    "                }\n",
    "            },\n",
    "            batch_size=[bs]\n",
    "        )\n",
    "        return out\n",
    "    \n",
    "    def _reset(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        if tensordict is None or tensordict.is_empty():\n",
    "            return TensorDict(\n",
    "            {\n",
    "                \"observation\": TensorDict({\n",
    "                        'a': torch.tensor([[-1, -2], [-4, -5]], dtype=torch.float),\n",
    "                        'b': torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float),\n",
    "                        },\n",
    "                        batch_size=[bs]\n",
    "                    ),\n",
    "            },\n",
    "            batch_size=[bs]\n",
    "        ) \n",
    "        return tensordict\n",
    "    \n",
    "    def _set_seed(self, seed: Optional[int]):\n",
    "        rng = torch.manual_seed(seed)\n",
    "        self.rng = rng\n",
    "\n",
    "    def _make_specs(self) -> None:\n",
    "        self.action_spec = UnboundedDiscreteTensorSpec(\n",
    "            dtype=torch.int,\n",
    "            shape=[bs]\n",
    "            # shape=(1,)\n",
    "            # shape=(self.model.tensors['o'].shape[0],)\n",
    "        )\n",
    "        observation_spec = CompositeSpec(\n",
    "            a = UnboundedContinuousTensorSpec(\n",
    "                dtype=torch.float32,\n",
    "                shape=[bs]\n",
    "            ),\n",
    "            b = UnboundedContinuousTensorSpec(\n",
    "                dtype=torch.float32,\n",
    "                shape=[bs]\n",
    "            ),\n",
    "            shape=[bs]\n",
    "        )\n",
    "        # if not isinstance(observation_spec, CompositeSpec):\n",
    "        observation_spec = CompositeSpec(observation=observation_spec, shape=[bs])\n",
    "            \n",
    "        self.observation_spec = observation_spec\n",
    "        self.reward_spec = UnboundedContinuousTensorSpec(\n",
    "            shape=[bs],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.done_spec = BinaryDiscreteTensorSpec(\n",
    "            bs,\n",
    "            shape=[bs]\n",
    "        )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "    TestEnv(),\n",
    "    # Compose(\n",
    "    #     # normalize observations\n",
    "    #     # ObservationNorm(in_keys=[\"observation\"]),\n",
    "    #     # DoubleToFloat(in_keys=[\"observation\"]),\n",
    "    #     StepCounter(),\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    observation: CompositeSpec(\n",
      "        a: UnboundedContinuousTensorSpec(\n",
      "             shape=torch.Size([2, 3]), space=None, device=cpu, dtype=torch.float32, domain=continuous),\n",
      "        b: UnboundedContinuousTensorSpec(\n",
      "             shape=torch.Size([2, 3]), space=None, device=cpu, dtype=torch.float32, domain=continuous), device=cpu, shape=torch.Size([2, 3])), device=cpu, shape=torch.Size([2]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "     shape=torch.Size([2]), space=None, device=cpu, dtype=torch.float32, domain=continuous)\n",
      "input_spec: CompositeSpec(\n",
      "    action: UnboundedDiscreteTensorSpec(\n",
      "         shape=torch.Size([2]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous), device=cpu, shape=torch.Size([2]))\n",
      "action_spec (as defined by input_spec): UnboundedDiscreteTensorSpec(\n",
      "     shape=torch.Size([2]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, contiguous=True), maximum=Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, contiguous=True)), device=cpu, dtype=torch.int32, domain=continuous)\n",
      "next\n",
      "next\n",
      "next\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The dtypes of the real and fake tensordict don't match for key next.done. Got fake=torch.int64 and real=torch.bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb Cell 17\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minput_spec:\u001b[39m\u001b[39m\"\u001b[39m, env\u001b[39m.\u001b[39minput_spec)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39maction_spec (as defined by input_spec):\u001b[39m\u001b[39m\"\u001b[39m, env\u001b[39m.\u001b[39maction_spec)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dbok/PycharmProjects/delivery-RL/delivery-RL/rl_training.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m check_env_specs(env)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torchrl/envs/utils.py:290\u001b[0m, in \u001b[0;36mcheck_env_specs\u001b[0;34m(env, return_contiguous, check_dtype, seed)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe shapes of the real and fake tensordict don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match for key \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot fake=\u001b[39m\u001b[39m{\u001b[39;00mfake_tensordict[key]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and real=\u001b[39m\u001b[39m{\u001b[39;00mreal_tensordict[key]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m         )\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m check_dtype \u001b[39mand\u001b[39;00m (fake_tensordict[key]\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m real_tensordict[key]\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m--> 290\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    291\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe dtypes of the real and fake tensordict don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt match for key \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot fake=\u001b[39m\u001b[39m{\u001b[39;00mfake_tensordict[key]\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m and real=\u001b[39m\u001b[39m{\u001b[39;00mreal_tensordict[key]\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m         )\n\u001b[1;32m    295\u001b[0m \u001b[39m# test dtypes\u001b[39;00m\n\u001b[1;32m    296\u001b[0m real_tensordict \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mrollout(\u001b[39m3\u001b[39m)  \u001b[39m# keep empty structures, for example dict()\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The dtypes of the real and fake tensordict don't match for key next.done. Got fake=torch.int64 and real=torch.bool."
     ]
    }
   ],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)\n",
    "print(\"input_spec:\", env.input_spec)\n",
    "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
    "\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        next.done: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        next.observation.a: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.observation.b: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.reward: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.a: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.b: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        reward: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([2]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "next\n",
      "next\n",
      "next\n",
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        next.done: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next.observation.a: Tensor(shape=torch.Size([2, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.observation.b: Tensor(shape=torch.Size([2, 3, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        next.reward: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.a: Tensor(shape=torch.Size([2, 3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        observation.b: Tensor(shape=torch.Size([2, 3, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        reward: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([2, 3]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "fake = env.fake_tensordict().flatten_keys(\".\")\n",
    "print(fake)\n",
    "\n",
    "real_tensordict = env.rollout(3, return_contiguous=True).flatten_keys(\".\")\n",
    "print(real_tensordict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tensordict = fake.unsqueeze(real_tensordict.batch_dims - 1).expand(*real_tensordict.shape).to_tensordict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        next.done: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        next.observation.a: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.observation.b: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        next.reward: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.a: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        observation.b: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([2, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([2, 3]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real_tensordict.apply(lambda x: torch.zeros_like(x)) == fake_tensordict.apply(lambda x: torch.zeros_like(x))\n",
    "# fake_tensordict\n",
    "fake_tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(3, 5)\n",
    "        self.f2 = nn.Linear(3, 5)\n",
    "\n",
    "        self.last = nn.Linear(5, 2)\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = self.f1(x)\n",
    "        y = self.f2(y)\n",
    "\n",
    "        return self.last(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7460, -0.8222]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3]], dtype=torch.float)\n",
    "y = torch.tensor([[1, 2, 3]], dtype=torch.float)\n",
    "n = Net()\n",
    "n(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_module = TensorDictModule(\n",
    "    n, in_keys=[('inp', \"x\"), ('inp', \"y\")], out_keys=[\"out\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_module(x=x, y=y)\n",
    "inp = TensorDict(\n",
    "    {\n",
    "        'inp': TensorDict({\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "        }, batch_size=())\n",
    "    },\n",
    "    batch_size=(1, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = policy_module(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9481, 0.0790], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
